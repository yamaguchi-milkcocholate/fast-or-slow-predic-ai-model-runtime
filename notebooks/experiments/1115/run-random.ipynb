{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"tags":[]},"outputs":[],"source":["import pickle\n","import numpy as np\n","import pandas as pd\n","import warnings\n","import itertools\n","import random\n","import gc\n","import torch\n","import os\n","from copy import deepcopy\n","from torch import nn\n","from torch.utils.data import Dataset\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torch_geometric.nn import GCNConv, Sequential\n","from tqdm.notebook import tqdm\n","from pathlib import Path\n","from dataclasses import dataclass, field\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","import wandb\n","from dataclasses import asdict\n","\n","sns.set()\n","\n","warnings.simplefilter(\"ignore\")\n","\n","GPU = \"cuda:0\""]},{"cell_type":"markdown","metadata":{},"source":["## データセットを準備\n"]},{"cell_type":"code","execution_count":12,"metadata":{"tags":[]},"outputs":[],"source":["rootdir = Path().resolve().parent.parent\n","inputdir = rootdir / \"data\" / \"predict-ai-model-runtime\"\n","node_feat_dir = rootdir / \"data\" / \"google-slow-vs-fastlayout7-85-dataset\"\n","tile_node_feat_dir = rootdir / \"data\" / \"extra-feat-1114\"\n","trans_node_feat_dir = rootdir / \"data\" / \"google-slow-vs-fastlayout6-92-dataset\"\n","trans_node_config_feat_dir = rootdir / \"data\" / \"google-slow-vs-fastlayout7-81-dataset\"\n","checkpointdir = Path().resolve() / \"out\" / \"ranknet\"\n","workdir = Path().resolve() / \"out\" / \"ranknet-random\"\n","workdir.mkdir(exist_ok=True, parents=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"tags":[]},"outputs":[],"source":["dataset_dict = {}\n","ignores = []\n","for ds in [\"train\", \"valid\", \"test\"]:\n","    records = []\n","    for arch, perm in itertools.product([\"nlp\", \"xla\"], [\"default\", \"random\"]):\n","        datadir = inputdir / f\"npz_all/npz/layout/{arch}/{perm}/{ds}\"\n","        for filepath in sorted(datadir.glob(\"*.npz\")):\n","            filename = str(filepath).split(\"/\")[-1].replace(\".npz\", \"\")\n","\n","            if (ds != \"test\") and ((\"mlperf\" in filename) or (\"openai\" in filename)):\n","                ignores.append(filepath)\n","                continue\n","            records.append(\n","                {\n","                    \"arch\": arch,\n","                    \"perm\": perm,\n","                    \"filename\": filename,\n","                    \"filepath\": filepath,\n","                    \"node_feat_filepath\": str(\n","                        node_feat_dir / arch / perm / ds / f\"{filename}.npz\"\n","                    ),\n","                    \"tile_node_feat_filepath\": str(\n","                        tile_node_feat_dir / arch / perm / ds / f\"{filename}.npz\"\n","                    ),\n","                    \"trans_node_feat_filepath\": str(\n","                        trans_node_feat_dir\n","                        / \"layout\"\n","                        / arch\n","                        / perm\n","                        / ds\n","                        / f\"{filename}.npz\"\n","                    ),\n","                    \"trans_node_config_filepath\": str(\n","                        trans_node_config_feat_dir\n","                        / arch\n","                        / perm\n","                        / ds\n","                        / f\"{filename}.npz\"\n","                    ),\n","                }\n","            )\n","    dataset_dict[ds] = pd.DataFrame(records)"]},{"cell_type":"code","execution_count":4,"metadata":{"tags":[]},"outputs":[],"source":["# for filepath in tqdm(ignores):\n","#     node_config_feat = np.load(filepath)[\"node_config_feat\"]\n","\n","#     for i in range(1, node_config_feat.shape[0]):\n","#         if not (node_config_feat[0] == node_config_feat[i]).all():\n","#             filepath\n","#             break"]},{"cell_type":"code","execution_count":5,"metadata":{"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>number</th>\n","      <th>num_dims</th>\n","      <th>num_cats</th>\n","      <th>cats</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>19</td>\n","      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>68</td>\n","      <td>6</td>\n","      <td>[0, 1, 2, 3, 4, 5]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   number  num_dims  num_cats  \\\n","0       0         1        19   \n","1       1        68         6   \n","\n","                                                cats  \n","0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n","1                                 [0, 1, 2, 3, 4, 5]  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["dfcat = pd.DataFrame(\n","    [\n","        {\"number\": 0, \"num_dims\": 1, \"num_cats\": 19, \"cats\": list(range(19))},\n","        {\"number\": 1, \"num_dims\": 54 + 14, \"num_cats\": 6, \"cats\": list(range(6))},\n","    ]\n",")\n","dfcat.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>number</th>\n","      <th>num_dims</th>\n","      <th>num_cats</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   number  num_dims  num_cats\n","0       0        18         8"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dfcat_config = pd.DataFrame(\n","    [\n","        {\n","            \"number\": 0,\n","            \"num_dims\": 18,\n","            \"num_cats\": 8,\n","        },  # output_layout, input_layout, kernel_layout\n","    ]\n",")\n","dfcat_config"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["for ds in dataset_dict:\n","    for i, row in dataset_dict[ds].iterrows():\n","        np.load(row[\"filepath\"])\n","        np.load(row[\"node_feat_filepath\"])\n","        np.load(row[\"tile_node_feat_filepath\"])\n","        np.load(row[\"trans_node_feat_filepath\"])\n","        np.load(row[\"trans_node_config_filepath\"])"]},{"cell_type":"markdown","metadata":{},"source":["# データクラスを定義\n"]},{"cell_type":"code","execution_count":9,"metadata":{"tags":[]},"outputs":[],"source":["@dataclass\n","class CatStatus:\n","    dfcat: pd.DataFrame\n","    prefix: str\n","    num_cat_dict: dict[str, int] = field(init=False)\n","    index_dict: dict[str, list[int]] = field(init=False)\n","\n","    def __post_init__(self) -> None:\n","        self.num_cat_dict, self.index_dict = {}, {}\n","        dim_start = 0\n","        for i, row in self.dfcat.iterrows():\n","            self.num_cat_dict[f\"{self.prefix}cat_feat{i + 1}\"] = row[\"num_cats\"]\n","            self.index_dict[f\"{self.prefix}cat_feat{i + 1}\"] = list(\n","                range(dim_start, dim_start + row[\"num_dims\"])\n","            )\n","            dim_start += row[\"num_dims\"]\n","\n","\n","cat_status = CatStatus(dfcat=dfcat, prefix=\"\")\n","cat_config_status = CatStatus(dfcat=dfcat_config, prefix=\"config_\")\n","\n","\n","@dataclass\n","class Const:\n","    num_node_flag_feat_dim: int\n","    num_node_cont_feat_dim: int\n","    num_node_cat_feat_dim: int\n","    num_node_config_cont_feat_dim: int\n","\n","    # 演算子の種類\n","    num_operations: int = 120\n","    # 各configの次元数\n","    num_config_dims: int = 6\n","\n","\n","fileobj = np.load(dataset_dict[\"train\"].iloc[0][\"node_feat_filepath\"])\n","tile_fileobj = np.load(dataset_dict[\"train\"].iloc[0][\"tile_node_feat_filepath\"])\n","trans_fileobj = np.load(dataset_dict[\"train\"].iloc[0][\"trans_node_feat_filepath\"])\n","trans_config_fileobj = np.load(\n","    dataset_dict[\"train\"].iloc[0][\"trans_node_config_filepath\"]\n",")\n","\n","node_flag_feat, node_cont_feat = fileobj[\"node_flag_feat\"], fileobj[\"node_cont_feat\"]\n","node_enum_feat, node_dimension_number_feat = (\n","    fileobj[\"node_enum_feat\"],\n","    fileobj[\"node_dimension_number_feat\"],\n",")\n","node_tile_cont_feat = tile_fileobj[\"node_feat\"]\n","trans_node_cont_feat, trans_node_cat_feat = (\n","    trans_fileobj[\"node_cont_feat\"],\n","    trans_fileobj[\"node_cat_feat\"],\n",")\n","trans_node_config_cont_feat = trans_config_fileobj[\"node_config_cont_feat\"]\n","const = Const(\n","    num_node_flag_feat_dim=node_flag_feat.shape[1] + 1,  # config_idsの分+1\n","    num_node_cont_feat_dim=node_cont_feat.shape[1]\n","    + trans_node_cont_feat.shape[1]\n","    + node_tile_cont_feat.shape[1],\n","    num_node_cat_feat_dim=node_enum_feat.shape[1]\n","    + node_dimension_number_feat.shape[1]\n","    + trans_node_cat_feat.shape[1],\n","    num_node_config_cont_feat_dim=trans_node_config_cont_feat.shape[2],\n",")\n","\n","\n","@dataclass\n","class NodeFeatExtractor:\n","    dims: list[int] = field(default_factory=lambda: [64, 64])\n","    leakyrelu_negative_slope: float = 0.1\n","    dropout_p: float = 0.1\n","\n","\n","@dataclass\n","class GNNExtractor:\n","    dims: list[int] = field(default_factory=lambda: [64, 64])\n","    leakyrelu_negative_slope = 0.1\n","    dropout_p: float = 0.1\n","\n","\n","@dataclass\n","class CatEmbedding:\n","    num_cat: int\n","    embedding_dim: int\n","\n","\n","@dataclass\n","class Params:\n","    device: str\n","    cat_embeddings: dict[str, CatEmbedding]\n","    random_batch_size: int = 25\n","    batch_size: int = 25\n","    node_feat_extractor: NodeFeatExtractor = field(\n","        default_factory=lambda: NodeFeatExtractor(dropout_p=0)\n","    )\n","    node_config_feat_extractor: NodeFeatExtractor = field(\n","        default_factory=lambda: NodeFeatExtractor(dropout_p=0)\n","    )\n","    gnn_extractor: GNNExtractor = field(\n","        default_factory=lambda: GNNExtractor(dropout_p=0)\n","    )\n","    subgraph_extractor: NodeFeatExtractor = field(\n","        default_factory=lambda: NodeFeatExtractor(dropout_p=0)\n","    )\n","    epoch: int = 20\n","    T_max: int = 20\n","    eta_min: float = 1e-5\n","    lr: float = 1e-3\n","    weight_decay: float = 0\n","    grad_clip_max_norm: float = 1.0\n","    grad_clip_norm_type: float = 2.0\n","\n","\n","cat_embeddings = {}\n","cat_embeddings.update(\n","    {\"op\": CatEmbedding(num_cat=const.num_operations, embedding_dim=16)}\n",")\n","cat_embeddings.update(\n","    {\n","        k: CatEmbedding(num_cat=v, embedding_dim=16)\n","        for k, v in cat_status.num_cat_dict.items()\n","    }\n",")\n","cat_embeddings.update(\n","    {\n","        k: CatEmbedding(num_cat=v, embedding_dim=8)\n","        for k, v in cat_config_status.num_cat_dict.items()\n","    }\n",")\n","params = Params(\n","    device=GPU if torch.cuda.is_available() else \"cpu\",\n","    cat_embeddings=cat_embeddings,\n",")\n","\n","\n","@dataclass\n","class LayoutConfigs:\n","    \"\"\"\n","    Attributes\n","    ----------\n","    node_cont_feat: np.ndarray\n","        ノード特徴量、(ノード数, 108)\n","\n","    node_cat_feat: np.ndarray\n","        ノード特徴量、(ノード数, 3)\n","\n","    node_opcode: np.ndarray\n","        ノード演算子、(ノード数,)\n","    edge_index: np.ndarray\n","        エッジ、(エッジ数, 2)\n","\n","    node_config_feat: np.ndarray\n","        設定毎のノード特徴量、(設定数, 設定可能なノード数, 3)\n","\n","    node_config_ids: np.ndarray\n","        設定可能なノードのIndex、(設定可能なノード数,)\n","    config_runtime: np.ndarray\n","        実行時間、(設定数,)\n","    node_splits: np.ndarray\n","        同じパーティションでの計算を意味する。今回は使用しない。(パーティション数, 2)\n","    \"\"\"\n","\n","    node_flag_feat: np.ndarray\n","    node_cont_feat: np.ndarray\n","    node_cat_feat: np.ndarray\n","    node_opcode: np.ndarray\n","    edge_index: np.ndarray\n","    node_config_feat: np.ndarray\n","    node_config_cont_feat: np.ndarray\n","    node_config_ids: np.ndarray\n","    config_runtime: np.ndarray\n","    node_splits: np.ndarray\n","\n","    cat_status: CatStatus\n","    cat_config_status: CatStatus\n","    target: np.ndarray = field(init=False)\n","    argsorted_indexs: list[int] = field(init=False)\n","\n","    NUM_SAMPLES: int = 1000\n","\n","    def __post_init__(self) -> None:\n","        # 設定が存在するノードのフラグ\n","        node_active_feat = np.zeros((self.num_nodes, 1))\n","        node_active_feat[self.node_config_ids, :] = 1\n","        self.node_flag_feat = np.concatenate(\n","            [self.node_flag_feat, node_active_feat], axis=1\n","        )\n","        self.node_cont_feat = self.apply_normalization(x=self.node_cont_feat)\n","        self.node_config_feat = self.node_config_feat + 1  # カテゴリは0~7にする\n","        self.node_splits = np.array(\n","            [\n","                [self.node_splits[0][i], self.node_splits[0][i + 1] - 1]\n","                for i in range(self.node_splits.shape[1] - 1)\n","            ]\n","        )\n","        self.target = self.apply_target_ranking(x=self.config_runtime)\n","        self.argsorted_indexs = np.argsort(self.config_runtime).tolist()\n","\n","    @property\n","    def num_nodes(self) -> int:\n","        \"\"\"ノード数\"\"\"\n","        return self.node_cont_feat.shape[0]\n","\n","    def get_random_config_idxs(self) -> list[int]:\n","        \"\"\"tpu_graphのサンプリング方法\n","        https://github.com/google-research-datasets/tpu_graphs/blob/main/tpu_graphs/baselines/layout/data.py#L352\n","        \"\"\"\n","        num_configs = self.config_runtime.shape[0]\n","        num_samples = min(self.NUM_SAMPLES, num_configs)\n","\n","        samples = random.sample(list(range(num_configs)), num_samples)\n","        return samples\n","\n","        # third = num_samples // 3\n","\n","        # middle_samples = np.random.choice(\n","        #     self.argsorted_indexs[third:-third], num_samples - 2 * third\n","        # ).tolist()\n","        # samples = (\n","        #     self.argsorted_indexs[:third]\n","        #     + self.argsorted_indexs[-third:]\n","        #     + middle_samples\n","        # )\n","        # samples = random.sample(samples, len(samples))\n","\n","        # return samples\n","\n","    def get_filled_node_config_feat(\n","        self, index_list: list[int]\n","    ) -> tuple[np.ndarray, np.ndarray]:\n","        \"\"\"指定された設定の設定毎のノード特徴量を取得する。設定がない場合は補完する。\n","        Parameters\n","        ----------\n","        index_list: list[int]\n","            設定のIndex\n","\n","        Returns\n","        -------\n","        np.ndarray [(len(index_list),ノード数, 18), (len(index_list),ノード数, 連続次元数)]\n","        \"\"\"\n","        # (サンプル数, ノード数) x 3\n","        node_config_feat = np.full(\n","            (len(index_list), self.num_nodes, Const.num_config_dims * 3),\n","            Const.num_config_dims + 1,\n","        )\n","        node_config_feat[:, self.node_config_ids] = self.node_config_feat[\n","            index_list, :, :\n","        ]\n","\n","        node_config_cont_feat = np.zeros(\n","            (len(index_list), self.num_nodes, self.node_config_cont_feat.shape[2])\n","        )\n","        node_config_cont_feat[:, self.node_config_ids] = self.node_config_cont_feat[\n","            index_list, :, :\n","        ]\n","        return node_config_feat, node_config_cont_feat\n","\n","    def get_target(self, index_list: list[int]) -> np.ndarray:\n","        \"\"\"指定された設定の目的変数を取得する\n","\n","        Parameters\n","        ----------\n","        index_list: list[int]\n","            設定のIndex\n","\n","        Returns\n","        -------\n","        np.ndarray\n","        \"\"\"\n","        return self.target[index_list]\n","\n","    def apply_normalization(self, x: np.ndarray) -> np.ndarray:\n","        \"\"\"特徴量の正規化\n","\n","        Parameters\n","        ----------\n","        x: np.ndarray\n","            2次元行列\n","\n","        Returns\n","        -------\n","        x: np.ndarray\n","            行方向に正規化された行列\n","        \"\"\"\n","        x /= 128\n","        x = np.where(x >= 0, np.log1p(x / 128), -np.log1p(-x / 128))\n","        return x\n","\n","    def apply_target_normalization(self, x: np.ndarray) -> np.ndarray:\n","        \"\"\"目的変数の正規化\n","\n","        Parameters\n","        ----------\n","        x: np.ndarray\n","            ベクトル\n","\n","        Returns\n","        -------\n","        x: np.ndarray\n","            正規化されたベクトル\n","        \"\"\"\n","        return np.log(x / x.min())\n","\n","    def apply_target_ranking(self, x: np.ndarray) -> np.ndarray:\n","        \"\"\"降順でランキング\"\"\"\n","        return np.argsort(np.argsort(-x))"]},{"cell_type":"markdown","metadata":{},"source":["## データセットを定義\n"]},{"cell_type":"code","execution_count":13,"metadata":{"tags":[]},"outputs":[],"source":["class LayoutDataset(Dataset):\n","    \"\"\"\n","    Attributes\n","    ----------\n","    rows: list[dict[str, np.ndarray]]\n","        設定をリストでもつ\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        dataset: pd.DataFrame,\n","        params: Params,\n","        cat_status: CatStatus,\n","        cat_config_status: CatStatus,\n","    ) -> None:\n","        self.rows = dataset.to_dict(\"records\")\n","        self.params = params\n","        self.cat_status = cat_status\n","        self.cat_config_status = cat_config_status\n","        self.cache_idx = None\n","        self.cache_filepath = None\n","\n","    @property\n","    def device(self) -> str:\n","        return self.params.device\n","\n","    def __len__(self) -> int:\n","        return len(self.rows)\n","\n","    def create_layout_config(self, idx: int) -> LayoutConfigs:\n","        if self.cache_idx != idx:\n","            self.cache_idx = idx\n","            fileobj = np.load(self.rows[self.cache_idx][\"filepath\"])\n","            node_feat_fileobj = np.load(self.rows[self.cache_idx][\"node_feat_filepath\"])\n","            tile_node_feat_fileobj = np.load(\n","                self.rows[self.cache_idx][\"tile_node_feat_filepath\"]\n","            )\n","            trans_feat_fileobj = np.load(\n","                self.rows[self.cache_idx][\"trans_node_feat_filepath\"]\n","            )\n","            trans_config_feat_fileobj = np.load(\n","                self.rows[self.cache_idx][\"trans_node_config_filepath\"]\n","            )\n","\n","            node_cont_feat = np.concatenate(\n","                [\n","                    node_feat_fileobj[\"node_cont_feat\"],\n","                    trans_feat_fileobj[\"node_cont_feat\"],\n","                    tile_node_feat_fileobj[\"node_feat\"],\n","                ],\n","                axis=1,\n","            )\n","\n","            node_cat_feat = np.concatenate(\n","                [\n","                    node_feat_fileobj[\"node_enum_feat\"],\n","                    node_feat_fileobj[\"node_dimension_number_feat\"],\n","                    trans_feat_fileobj[\"node_cat_feat\"],\n","                ],\n","                axis=1,\n","            )\n","\n","            self.cache_layout_config = LayoutConfigs(\n","                node_opcode=fileobj[\"node_opcode\"],\n","                edge_index=fileobj[\"edge_index\"],\n","                node_config_ids=fileobj[\"node_config_ids\"],\n","                config_runtime=fileobj[\"config_runtime\"],\n","                node_splits=fileobj[\"node_splits\"],\n","                node_flag_feat=node_feat_fileobj[\"node_flag_feat\"],\n","                node_cont_feat=node_cont_feat,\n","                node_cat_feat=node_cat_feat,\n","                node_config_feat=fileobj[\"node_config_feat\"],\n","                node_config_cont_feat=trans_config_feat_fileobj[\n","                    \"node_config_cont_feat\"\n","                ],\n","                cat_status=self.cat_status,\n","                cat_config_status=self.cat_config_status,\n","            )\n","        return self.cache_layout_config\n","\n","    def __getitem__(\n","        self, idx: int\n","    ) -> tuple[\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","    ]:\n","        raise NotImplementedError()\n","\n","    def getitem_as_random_batch(\n","        self, idx: int\n","    ) -> list[\n","        tuple[\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","        ]\n","    ]:\n","        layout_configs = self.create_layout_config(idx=idx)\n","\n","        index_list = layout_configs.get_random_config_idxs()\n","        for i_chunk in range(0, len(index_list), self.params.random_batch_size):\n","            chunk_index_list = index_list[\n","                i_chunk : i_chunk + self.params.random_batch_size\n","            ]\n","            yield self._get_tensors(\n","                layout_configs=layout_configs, index_list=chunk_index_list\n","            )\n","\n","    def getitem_as_batch(\n","        self, idx: int\n","    ) -> list[\n","        tuple[\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","        ]\n","    ]:\n","        \"\"\"設定をバッチで取得する\"\"\"\n","        layout_configs = self.create_layout_config(idx=idx)\n","\n","        index_list = list(range(layout_configs.config_runtime.shape[0]))\n","        for i_chunk in range(0, len(index_list), self.params.batch_size):\n","            chunk_index_list = index_list[i_chunk : i_chunk + self.params.batch_size]\n","            yield self._get_tensors(\n","                layout_configs=layout_configs, index_list=chunk_index_list\n","            )\n","\n","    def _get_tensors(\n","        self, layout_configs: LayoutConfigs, index_list: list[int]\n","    ) -> tuple[\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","    ]:\n","        \"\"\"渡された設定のIndexのテンソルを取得する\n","\n","        Parameters\n","        ----------\n","        layout_configs: LayoutConfigs\n","            Layoutのデータクラス\n","        index_list: list[int]\n","            設定のインデックス\n","\n","        Returns\n","        -------\n","        torch.Tensor\n","            ノード特徴量(フラグ)\n","        torch.Tensor\n","            ノード特徴量(連続)\n","        dict[str, torch.Tensor]\n","            ノード特徴量(カテゴリ)\n","        torch.Tensor\n","            設定毎のノード特徴量\n","        torch.Tensor\n","            設定毎のノード特徴量(連続)\n","        torch.Tensor\n","            ノード演算子\n","        torch.Tensor\n","            エッジ\n","        torch.Tensor\n","            目的変数\n","        \"\"\"\n","        # ノード特徴量(フラグ)\n","        node_flag_feat = torch.tensor(\n","            layout_configs.node_flag_feat,\n","            dtype=torch.float32,\n","        ).to(self.device)\n","        # ノード特徴量(連続)\n","        node_cont_feat = torch.tensor(\n","            layout_configs.node_cont_feat,\n","            dtype=torch.float32,\n","        ).to(self.device)\n","        # ノード特徴量(カテゴリ)\n","        node_cat_feat = torch.tensor(\n","            layout_configs.node_cat_feat,\n","            dtype=torch.int64,\n","        ).to(self.device)\n","        # 設定毎のノード特徴量(カテゴリ)\n","        (\n","            node_config_feat,\n","            node_config_cont_feat,\n","        ) = layout_configs.get_filled_node_config_feat(index_list=index_list)\n","        node_config_feat = torch.tensor(node_config_feat, dtype=torch.int64).to(\n","            self.device\n","        )\n","        node_config_cont_feat = torch.tensor(\n","            node_config_cont_feat, dtype=torch.float32\n","        ).to(self.device)\n","        # ノード演算子\n","        node_opcode = torch.tensor(layout_configs.node_opcode, dtype=torch.int64).to(\n","            self.device\n","        )\n","        # エッジ\n","        edge_index = torch.tensor(\n","            np.swapaxes(layout_configs.edge_index, 0, 1), dtype=torch.int64\n","        ).to(self.device)\n","        # サブグラフ\n","        node_splits = torch.tensor(layout_configs.node_splits, dtype=torch.int64).to(\n","            self.device\n","        )\n","        # 設定のids\n","        node_config_ids = torch.tensor(\n","            layout_configs.node_config_ids, dtype=torch.int64\n","        ).to(self.device)\n","        # ターゲット\n","        target = torch.tensor(\n","            layout_configs.get_target(index_list=index_list),\n","            dtype=torch.float32,\n","        ).to(self.device)\n","\n","        return (\n","            node_opcode,\n","            node_flag_feat,\n","            node_cont_feat,\n","            node_cat_feat,\n","            node_config_feat,\n","            node_config_cont_feat,\n","            edge_index,\n","            node_splits,\n","            node_config_ids,\n","            target,\n","        )\n","\n","    def get_ith_file_info(self, i: int) -> dict[str, str]:\n","        row = self.rows[i]\n","        return {\n","            \"arch\": row[\"arch\"],\n","            \"perm\": row[\"perm\"],\n","            \"filename\": row[\"filename\"],\n","        }\n","\n","    def get_ith_runtime(self, i: int) -> np.ndarray:\n","        layout_configs = self.create_layout_config(idx=i)\n","        return layout_configs.config_runtime"]},{"cell_type":"markdown","metadata":{},"source":["## モデルを定義\n"]},{"cell_type":"code","execution_count":14,"metadata":{"tags":[]},"outputs":[],"source":["from torch_geometric.nn import MessagePassing\n","\n","\n","class EdgeConv(MessagePassing):\n","    \"\"\"\n","    ノード特徴 + 隣接ノード特徴 + 隣接ノード特徴の一致\n","    参考： https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_gnn.html#implementing-the-edge-convolution\n","    補足: 集約関数はデフォルトでdim(axis) = -2。つまりノード方向で集約するので気にしなくてOK\n","    https://github.com/pyg-team/pytorch_geometric/blob/1e12d41c28b1fb9793f17646b018071b508864d7/torch_geometric/nn/aggr/basic.py#L38\n","    \"\"\"\n","\n","    def __init__(self, x_input_dim: int, x_output_dim: int, dropout_p: float):\n","        # \"Add\" aggregation\n","        super().__init__(aggr=\"max\")\n","        self.mlp = nn.Sequential(\n","            nn.Dropout(dropout_p),\n","            # nn.LayerNorm(x_input_dim * 2),\n","            nn.Linear(x_input_dim * 2, x_output_dim),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_p),\n","            # nn.LayerNorm(x_output_dim),\n","            nn.Linear(x_output_dim, x_output_dim),\n","        )\n","\n","    def forward(self, x, edge_index):\n","        # x has shape [設定数, N, in_channels]\n","        # edge_index has shape [2, E]\n","        return self.propagate(edge_index, x=x)\n","\n","    def message(self, x_i, x_j):\n","        \"\"\"propagate()で渡された引数xから自動でx_i, x_jノードを取り出して随時処理を実装する関数\"\"\"\n","        # x_i has shape [設定数, エッジ数, in_channels]\n","        # x_j has shape [設定数, エッジ数, in_channels]\n","        x_cat = torch.cat(\n","            [x_i, x_i - x_j], dim=2\n","        )  # tmp has shape [設定数, エッジ数, 2 * in_channels]\n","        return self.mlp(x_cat)\n","\n","\n","class SimpleLayoutModel(torch.nn.Module):\n","    \"\"\"\n","\n","    Attributes\n","    ----------\n","    params: Params\n","        実験設定のデータクラス\n","    node_embeddings: torch.Tensor\n","        カテゴリ変数の埋め込み表現(ノード毎)\n","    node_config_embeddings: torch.Tensor\n","        カテゴリ変数の埋め込み表現(設定xノード毎)\n","    node_feat_extractor: torch.nn.Module\n","        ノードの特徴量を抽出するネットワーク\n","    gnn_extractor: torch.nn.Module\n","        グラフの特徴量を抽出するネットワーク\n","    gc: torch.nn.Module\n","        最終層の全結合層\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        params: Params,\n","        const: Const,\n","        cat_status: CatStatus,\n","        cat_config_status: CatStatus,\n","    ) -> None:\n","        super().__init__()\n","        self.params = params\n","        self.cat_status = cat_status\n","        self.cat_config_status = cat_config_status\n","\n","        # カテゴリ変数の埋め込み表現\n","        self.embeddings = nn.ModuleDict(\n","            {\n","                k: torch.nn.Embedding(v.num_cat, v.embedding_dim)\n","                for k, v in self.params.cat_embeddings.items()\n","            }\n","        )\n","\n","        # node_featのfeature_extractorを定義\n","        num_node_feat_extractor_input_dim = (\n","            const.num_node_flag_feat_dim\n","            + const.num_node_cont_feat_dim\n","            + self.num_node_feat_embedding_dims\n","        )\n","\n","        node_feat_extractor_layer = []\n","        node_feat_extractor_dims = [\n","            num_node_feat_extractor_input_dim\n","        ] + self.params.node_feat_extractor.dims\n","        for i in range(len(node_feat_extractor_dims) - 1):\n","            node_feat_extractor_layer += [\n","                # nn.LayerNorm(node_feat_extractor_dims[i]),\n","                nn.Dropout(params.node_feat_extractor.dropout_p),\n","                nn.Linear(\n","                    in_features=node_feat_extractor_dims[i],\n","                    out_features=node_feat_extractor_dims[i + 1],\n","                ),\n","                nn.LeakyReLU(params.node_feat_extractor.leakyrelu_negative_slope),\n","            ]\n","            self.node_feat_extractor = nn.Sequential(*node_feat_extractor_layer)\n","\n","        # node_config_featのfeature_extractorを定義\n","        num_node_config_feat_extractor_input_dim = (\n","            self.num_node_config_feat_embedding_dims\n","            + const.num_node_config_cont_feat_dim\n","        )\n","\n","        node_config_feat_extractor_layer = []\n","        node_config_feat_extractor_dims = [\n","            num_node_config_feat_extractor_input_dim\n","        ] + self.params.node_config_feat_extractor.dims\n","        for i in range(len(node_feat_extractor_dims) - 1):\n","            node_config_feat_extractor_layer += [\n","                # nn.LayerNorm(node_config_feat_extractor_dims[i]),\n","                nn.Dropout(params.node_config_feat_extractor.dropout_p),\n","                nn.Linear(\n","                    in_features=node_config_feat_extractor_dims[i],\n","                    out_features=node_config_feat_extractor_dims[i + 1],\n","                ),\n","                nn.LeakyReLU(\n","                    params.node_config_feat_extractor.leakyrelu_negative_slope\n","                ),\n","            ]\n","        self.node_config_feat_extractor = nn.Sequential(\n","            *node_config_feat_extractor_layer\n","        )\n","\n","        # ノード間のfeature_extractorの定義\n","        num_gnn_extractor_input_dim = (\n","            node_feat_extractor_dims[-1] + node_config_feat_extractor_dims[-1]\n","        )\n","\n","        gnn_extractor_layer = []\n","        gnn_extractor_dims = [\n","            num_gnn_extractor_input_dim\n","        ] + self.params.gnn_extractor.dims\n","        for i in range(len(gnn_extractor_dims) - 1):\n","            gnn_extractor_layer += [\n","                (\n","                    EdgeConv(\n","                        x_input_dim=gnn_extractor_dims[i],\n","                        x_output_dim=gnn_extractor_dims[i + 1],\n","                        dropout_p=params.gnn_extractor.dropout_p,\n","                    ),\n","                    \"x, edge_index -> x\",\n","                ),\n","                nn.LeakyReLU(params.gnn_extractor.leakyrelu_negative_slope),\n","            ]\n","        self.gnn_extractor = Sequential(\"x, edge_index\", gnn_extractor_layer)\n","\n","        fc_layer = [\n","            # nn.LayerNorm(subgraph_extractor_dims[-1]),\n","            # nn.Linear(in_features=subgraph_extractor_dims[-1], out_features=1),\n","            nn.Linear(\n","                in_features=self.params.gnn_extractor.dims[-1]\n","                + num_gnn_extractor_input_dim,\n","                out_features=1,\n","            ),\n","        ]\n","        self.fc = nn.Sequential(*fc_layer)\n","        self.to(self.params.device)\n","\n","    @property\n","    def num_node_feat_embedding_dims(self) -> int:\n","        num_embedding_dims = 0\n","        num_embedding_dims += 1 * self.params.cat_embeddings[\"op\"].embedding_dim\n","        for cat_name, cat_index in self.cat_status.index_dict.items():\n","            num_embedding_dims += (\n","                len(cat_index) * self.params.cat_embeddings[cat_name].embedding_dim\n","            )\n","        return num_embedding_dims\n","\n","    @property\n","    def num_node_config_feat_embedding_dims(self) -> int:\n","        num_embedding_dims = 0\n","        for cat_name, cat_index in self.cat_config_status.index_dict.items():\n","            num_embedding_dims += (\n","                len(cat_index) * self.params.cat_embeddings[cat_name].embedding_dim\n","            )\n","        return num_embedding_dims\n","\n","    def forward(\n","        self,\n","        node_opcode: torch.Tensor,\n","        node_flag_feat: torch.Tensor,\n","        node_cont_feat: torch.Tensor,\n","        node_cat_feat: torch.Tensor,\n","        node_config_feat: torch.Tensor,\n","        node_config_cont_feat: torch.Tensor,\n","        edge_index: torch.Tensor,\n","        node_splits: torch.Tensor,\n","        node_config_ids: torch.Tensor,\n","    ) -> torch.Tensor:\n","        \"\"\"\n","        Parameters\n","        ------\n","        node_flag_feat:\n","            ノードの特徴量(node数, フラグ次元数)\n","        node_cont_feat:\n","            ノードの特徴量(node数, 連続次元数)\n","        node_cat_feat:\n","            ノードの特徴量(node数, カテゴリ次元数*埋め込み次元数)\n","        node_config_feat:\n","            設定毎のノードの特徴量(設定数, node数, 特徴次元数)\n","        node_config_cont_feat:\n","            設定毎のノードの特徴量(設定数, node数, 連続次元数)\n","        edge_index:\n","            エッジ(2, エッジ数)\n","        node_splits:\n","            サブグラフのインデックス（サブグラフ数, 2)\n","\n","        Returns:\n","        torch.tensor: (設定数)\n","        \"\"\"\n","        # (ノード数,特徴数)のテンソルを作成\n","        node_feat = self._join_node_feature(\n","            node_opcode=node_opcode,\n","            node_flag_feat=node_flag_feat,\n","            node_cont_feat=node_cont_feat,\n","            node_cat_feat=node_cat_feat,\n","        )\n","\n","        # (設定数,ノード数,特徴数)のテンソルを作成\n","        node_config_feat = self._join_node_config_feature(\n","            node_config_feat=node_config_feat,\n","            node_config_cont_feat=node_config_cont_feat,\n","        )\n","\n","        # node_featの抽出器を通す\n","        extracted_node_feat = self.node_feat_extractor(node_feat)\n","\n","        # node_config_featの抽出器を通す\n","        extracted_node_config_feat = self.node_config_feat_extractor(node_config_feat)\n","\n","        # 設定毎のノード特徴に結合する\n","        extracted_feat = self._join_entire_node_config_feat(\n","            node_feat=extracted_node_feat,\n","            node_config_feat=extracted_node_config_feat,\n","        )\n","\n","        # GNN抽出器を通す\n","        conved_extracted_feat = self.gnn_extractor(\n","            x=extracted_feat,\n","            edge_index=edge_index,\n","        )\n","\n","        # 残差を足すイメージ\n","        concat_feat = torch.concat([extracted_feat, conved_extracted_feat], 2)\n","        concat_feat = concat_feat[:, node_config_ids, :]\n","\n","        # ノードの特徴量を足し合わせる(Global mean Pooling)\n","        # global_pool_feat = torch.mean(subgraph_extracted_feat, dim=1)\n","        global_pool_feat = torch.mean(concat_feat, dim=1)\n","\n","        return torch.squeeze(self.fc(global_pool_feat))\n","\n","    def _join_node_feature(\n","        self,\n","        node_opcode: torch.Tensor,\n","        node_flag_feat: torch.Tensor,\n","        node_cont_feat: torch.Tensor,\n","        node_cat_feat: torch.Tensor,\n","    ) -> torch.Tensor:\n","        \"\"\"node_featのテンソルを作成\"\"\"\n","        # ノードの埋め込み表現\n","        node_embeddings_list = []\n","        node_embeddings_list.append(self.embeddings[\"op\"](node_opcode))\n","        for cat_name, cat_index in self.cat_status.index_dict.items():\n","            node_embeddings = self.embeddings[cat_name](node_cat_feat[:, cat_index])\n","            node_embeddings = torch.reshape(\n","                node_embeddings,\n","                (-1, node_embeddings.shape[-2] * node_embeddings.shape[-1]),\n","            )\n","            node_embeddings_list.append(node_embeddings)\n","\n","        # ノード毎で埋め込み、結合(ノード数, 特徴数)\n","        node_embedding_feat = torch.concat(node_embeddings_list, 1)\n","        node_feat = torch.concat(\n","            [node_flag_feat, node_cont_feat, node_embedding_feat], 1\n","        )\n","        return node_feat\n","\n","    def _join_node_config_feature(\n","        self, node_config_feat: torch.Tensor, node_config_cont_feat: torch.Tensor\n","    ) -> torch.Tensor:\n","        \"\"\"node_config_featのテンソルを作成\"\"\"\n","        # 設定xノード毎で埋め込み(設定数, ノード数, 特徴数)\n","        node_config_embeddings_list = []\n","        for cat_name, cat_index in self.cat_config_status.index_dict.items():\n","            node_embeddings = self.embeddings[cat_name](\n","                node_config_feat[:, :, cat_index]\n","            )\n","            node_embeddings = torch.reshape(\n","                node_embeddings,\n","                (\n","                    node_embeddings.shape[0],\n","                    -1,\n","                    node_embeddings.shape[-2] * node_embeddings.shape[-1],\n","                ),\n","            )\n","            node_config_embeddings_list.append(node_embeddings)\n","        node_config_feat = torch.concat(\n","            node_config_embeddings_list + [node_config_cont_feat], 2\n","        )\n","        return node_config_feat\n","\n","    def _join_entire_node_config_feat(\n","        self, node_feat: torch.Tensor, node_config_feat: torch.Tensor\n","    ) -> torch.Tensor:\n","        # ノード毎の特徴量を設定数だけ縦に並べる\n","        node_tiled_feat = torch.tile(\n","            torch.reshape(node_feat, (1, node_feat.shape[0], node_feat.shape[1])),\n","            (node_config_feat.shape[0], 1, 1),\n","        )\n","        return torch.concat([node_tiled_feat, node_config_feat], 2)"]},{"cell_type":"markdown","metadata":{},"source":["## 学習\n"]},{"cell_type":"code","execution_count":15,"metadata":{"tags":[]},"outputs":[],"source":["class ListMLE(nn.Module):\n","    def __init__(self) -> None:\n","        super().__init__()\n","\n","    def forward(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","\n","        Parameters\n","        ----------\n","        logits: torch.Tensor\n","            予測（要素数, ）\n","        labels: torch.Tensor\n","            目的変数（要素数, ）\n","\n","        Returns\n","        -------\n","        torch.Tensor\n","        \"\"\"\n","        # 正解をソート\n","        labels_sorted, labels_sorted_indice = labels.sort(descending=True, dim=1)\n","        # 予測を正解順でソート\n","        logits_sorted_by_true = torch.gather(logits, dim=1, index=labels_sorted_indice)\n","        # 予測値の最大値で予測値を引く（expの爆発予防）\n","        logits_max, _ = logits_sorted_by_true.max(dim=1, keepdim=True)\n","        logits_sorted_by_true = logits_sorted_by_true - logits_max\n","        # ランキングが低いものから累積する(その後正解順に戻す)\n","        cumsums = torch.cumsum(logits_sorted_by_true.exp().flip(dims=[1]), dim=1).flip(\n","            dims=[1]\n","        )\n","        # 誤差\n","        negative_log_likelihood = torch.sum(\n","            torch.log(cumsums) - logits_sorted_by_true, dim=1\n","        )\n","        return torch.mean(negative_log_likelihood)\n","\n","\n","def rankNet(y_pred, y_true):\n","    \"\"\"\n","    RankNet loss introduced in \"Learning to Rank using Gradient Descent\".\n","    :param y_pred: predictions from the model, shape [batch_size, slate_length]\n","    :param y_true: ground truth labels, shape [batch_size, slate_length]\n","    :return: loss value, a torch.Tensor\n","    \"\"\"\n","    y_pred = y_pred.clone()\n","    y_true = y_true.clone()\n","\n","    # here we generate every pair of indices from the range of document length in the batch\n","    document_pairs_candidates = list(\n","        itertools.product(range(y_true.shape[1]), repeat=2)\n","    )\n","\n","    pairs_true = y_true[:, document_pairs_candidates]\n","    selected_pred = y_pred[:, document_pairs_candidates]\n","\n","    # here we calculate the relative true relevance of every candidate pair\n","    true_diffs = pairs_true[:, :, 0] - pairs_true[:, :, 1]\n","    pred_diffs = selected_pred[:, :, 0] - selected_pred[:, :, 1]\n","\n","    # here we filter just the pairs that are 'positive' and did not involve a padded instance\n","    # we can do that since in the candidate pairs we had symetric pairs so we can stick with\n","    # positive ones for a simpler loss function formulation\n","    the_mask = (true_diffs > 0) & (~torch.isinf(true_diffs))\n","\n","    pred_diffs = pred_diffs[the_mask]\n","\n","    weight = None\n","    # here we 'binarize' true relevancy diffs since for a pairwise loss we just need to know\n","    # whether one document is better than the other and not about the actual difference in\n","    # their relevancy levels\n","    true_diffs = (true_diffs > 0).type(torch.float32)\n","    true_diffs = true_diffs[the_mask]\n","\n","    return nn.BCEWithLogitsLoss(weight=weight)(pred_diffs, true_diffs)\n","\n","\n","def to_cpu_numpy(\n","    params: Params, pred: torch.Tensor, truth: torch.Tensor\n",") -> tuple[np.ndarray, np.ndarray]:\n","    if params.device == GPU:\n","        pred_ = pred.cpu().detach().numpy()\n","        truth_ = truth.cpu().detach().numpy()\n","        torch.cuda.empty_cache()\n","    else:\n","        pred_ = pred.detach().numpy()\n","        truth_ = truth.detach().numpy()\n","    return pred_, truth_"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["from scipy.stats import kendalltau\n","\n","\n","def evaluate_score(dataset: LayoutDataset, model: torch.nn.Module) -> pd.DataFrame:\n","    \"\"\"データセット全件に対してコンペの評価指標を算出する\n","    https://www.kaggle.com/competitions/predict-ai-model-runtime/overview\n","    \"\"\"\n","    model.eval()\n","    # criterion = ListMLE()\n","\n","    records = []\n","    eval_preds = []\n","    # 各グラフ毎にスコアを算出\n","    for graph_index in range(len(dataset)):\n","        # グラフ毎に1000件をバッチに分けて取得\n","        preds, truths = [], []\n","        for (\n","            node_opcode,\n","            node_flag_feat,\n","            node_cont_feat,\n","            node_cat_feat,\n","            node_config_feat,\n","            node_config_cont_feat,\n","            edge_index,\n","            node_splits,\n","            node_config_ids,\n","            target,\n","        ) in dataset.getitem_as_random_batch(graph_index):\n","            pred = model(\n","                node_opcode=node_opcode,\n","                node_flag_feat=node_flag_feat,\n","                node_cont_feat=node_cont_feat,\n","                node_cat_feat=node_cat_feat,\n","                node_config_feat=node_config_feat,\n","                node_config_cont_feat=node_config_cont_feat,\n","                edge_index=edge_index,\n","                node_splits=node_splits,\n","                node_config_ids=node_config_ids,\n","            )\n","            pred, truth = to_cpu_numpy(params, pred, target)\n","            preds.append(pred)\n","            truths.append(truth)\n","\n","        preds, truths = np.hstack(preds), np.hstack(truths)\n","\n","        loss = rankNet(\n","            torch.tensor(preds.reshape(1, -1)),\n","            torch.tensor(truths.reshape(1, -1)),\n","        )\n","        graph_loss = loss.item()\n","        score = kendalltau(truths, preds).correlation\n","\n","        record = dataset.get_ith_file_info(graph_index)\n","        record.update(\n","            {\n","                \"graph_loss\": graph_loss,\n","                \"score\": score,\n","            }\n","        )\n","        records.append(record)\n","        eval_preds.append(preds)\n","    return pd.DataFrame(records), eval_preds"]},{"cell_type":"markdown","metadata":{},"source":["### 学習\n"]},{"cell_type":"code","execution_count":21,"metadata":{"tags":[]},"outputs":[],"source":["def seed_everything(seed=1234):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","\n","def train_model(\n","    dftrain: pd.DataFrame,\n","    dfvalid: pd.DataFrame,\n","    params: Params,\n","    const: Const,\n","    cat_status: CatStatus,\n","    cat_config_status: CatStatus,\n","    savedir: Path,\n","    checkpointdir: Path = None,\n",") -> None:\n","    train_layout_dataset = LayoutDataset(\n","        dataset=dftrain,\n","        params=params,\n","        cat_status=cat_status,\n","        cat_config_status=cat_config_status,\n","    )\n","    valid_layout_dataset = LayoutDataset(\n","        dataset=dfvalid,\n","        params=params,\n","        cat_status=cat_status,\n","        cat_config_status=cat_config_status,\n","    )\n","\n","    model = SimpleLayoutModel(\n","        params=params,\n","        const=const,\n","        cat_status=cat_status,\n","        cat_config_status=cat_config_status,\n","    )\n","    if checkpointdir is not None:\n","        print(\"学習済みモデルを読み込みます\")\n","        model.load_state_dict(torch.load(checkpointdir / f\"final_model.pt\"))\n","\n","    optimizer = torch.optim.Adam(\n","        model.parameters(), lr=params.lr, weight_decay=params.weight_decay\n","    )\n","    scheduler = CosineAnnealingLR(\n","        optimizer=optimizer, T_max=params.T_max, eta_min=params.eta_min\n","    )\n","    # criterion = ListMLE()\n","\n","    best_score = -np.inf\n","    records = []\n","    num_train_log, num_valid_log = 0, 0\n","    for epoch in range(params.epoch):\n","        model.train()\n","\n","        num_graph = len(train_layout_dataset)\n","        pbar = tqdm(range(num_graph))\n","        graph_indexes = random.sample(list(range(num_graph)), num_graph)\n","\n","        epoch_losses = []\n","        epoch_loss = 0  # 各グラフの誤差を総和（エポックの誤差）\n","\n","        # グラフをシャッフルして取得\n","        for i_graph, graph_index in enumerate(graph_indexes):\n","            graph_info = train_layout_dataset.get_ith_file_info(graph_index)\n","            graph_arch, graph_perm = graph_info[\"arch\"], graph_info[\"perm\"]\n","            # 各グラフで1000件をバッチに分けて取得\n","            preds, truths = [], []\n","            graph_loss = 0  # バッチの誤差を総和（グラフの誤差）\n","            num_batch_count = 0\n","            for (\n","                node_opcode,\n","                node_flag_feat,\n","                node_cont_feat,\n","                node_cat_feat,\n","                node_config_feat,\n","                node_config_cont_feat,\n","                edge_index,\n","                node_splits,\n","                node_config_ids,\n","                target,\n","            ) in train_layout_dataset.getitem_as_random_batch(graph_index):\n","                out = model(\n","                    node_opcode=node_opcode,\n","                    node_flag_feat=node_flag_feat,\n","                    node_cont_feat=node_cont_feat,\n","                    node_cat_feat=node_cat_feat,\n","                    node_config_feat=node_config_feat,\n","                    node_config_cont_feat=node_config_cont_feat,\n","                    edge_index=edge_index,\n","                    node_splits=node_splits,\n","                    node_config_ids=node_config_ids,\n","                )\n","                # loss = criterion(\n","                #     torch.reshape(out, (1, out.shape[0])),\n","                #     torch.reshape(target, (1, target.shape[0])),\n","                # )\n","                loss = rankNet(\n","                    torch.reshape(out, (1, out.shape[0])),\n","                    torch.reshape(target, (1, target.shape[0])),\n","                )\n","                loss.backward()\n","                graph_loss += loss.item()\n","\n","                pred, truth = to_cpu_numpy(params, out, target)\n","                preds.append(pred)\n","                truths.append(truth)\n","                num_batch_count += 1\n","\n","            # 各グラフ毎に勾配降下\n","            nn.utils.clip_grad_norm_(\n","                model.parameters(),\n","                max_norm=params.grad_clip_max_norm,\n","                norm_type=params.grad_clip_norm_type,\n","            )\n","            optimizer.step()\n","            scheduler.step(epoch + i_graph / num_graph)\n","            optimizer.zero_grad()\n","\n","            preds, truths = np.hstack(preds), np.hstack(truths)\n","            score = kendalltau(truths, preds).correlation\n","            graph_loss /= num_batch_count  # 各バッチの平均をグラフの誤差とする\n","            epoch_loss += graph_loss\n","\n","            record = {\n","                \"epoch\": epoch,\n","                \"i_graph\": i_graph,\n","                \"num_train_log\": num_train_log,\n","                f\"train-{graph_arch}-{graph_perm}/epoch_loss\": epoch_loss\n","                / (i_graph + 1),\n","                f\"train/epoch_loss\": epoch_loss / (i_graph + 1),\n","                f\"train-{graph_arch}-{graph_perm}/graph_loss\": graph_loss,\n","                f\"train/graph_loss\": graph_loss,\n","                f\"train-{graph_arch}-{graph_perm}/score\": score,\n","                f\"train/score\": score,\n","                \"lr\": scheduler.get_last_lr()[0],\n","                f\"train-{graph_arch}-{graph_perm}/pred\": preds,\n","                f\"train/pred\": preds,\n","            }\n","            record.update(graph_info)\n","            records.append(record)\n","\n","            wandb.log(record)\n","            num_train_log += 1\n","            pbar.set_description(\n","                f\"running loss: {epoch_loss / (i_graph + 1):.5f}, graph loss: {graph_loss:.5f} score: {score:.3f}\"\n","            )\n","            pbar.update(1)\n","\n","        model.eval()\n","        torch.cuda.empty_cache()\n","\n","        dfscore, eval_preds = evaluate_score(dataset=valid_layout_dataset, model=model)\n","        avg_loss = dfscore[\"graph_loss\"].mean()\n","        avg_score = dfscore[\"score\"].mean()\n","        for i_eval, row_score in dfscore.iterrows():\n","            graph_arch, graph_perm = row_score[\"arch\"], row_score[\"perm\"]\n","            record = {\n","                \"epoch\": epoch,\n","                \"i_graph\": -1,\n","                \"num_valid_log\": num_valid_log,\n","                \"arch\": graph_arch,\n","                \"perm\": graph_perm,\n","                \"filename\": row_score[\"filename\"],\n","                f\"valid-{graph_arch}-{graph_perm}/epoch_loss\": avg_loss,\n","                f\"valid/epoch_loss\": avg_loss,\n","                f\"valid-{graph_arch}-{graph_perm}/graph_loss\": row_score[\"graph_loss\"],\n","                f\"valid/graph_loss\": row_score[\"graph_loss\"],\n","                f\"valid-{graph_arch}-{graph_perm}/score\": row_score[\"score\"],\n","                f\"valid/score\": row_score[\"score\"],\n","                \"lr\": scheduler.get_last_lr()[0],\n","                f\"valid-{graph_arch}-{graph_perm}/pred\": eval_preds[i_eval],\n","                f\"valid/pred\": eval_preds[i_eval],\n","            }\n","            records.append(record)\n","            wandb.log(record)\n","            num_valid_log += 1\n","\n","        print(f\"[valid] current loss: {avg_loss:.5f} score: {avg_score:.3f}\")\n","\n","        if best_score < avg_score:\n","            best_score = avg_score\n","            torch.save(model.state_dict(), savedir / \"best_model.pt\")\n","        torch.save(model.state_dict(), savedir / f\"epoch{epoch + 1}_model.pt\")\n","\n","    dflog = pd.DataFrame(records)\n","    dflog.to_csv(savedir / \"log.csv\", index=False)\n","\n","    torch.save(model.state_dict(), savedir / \"final_model.pt\")\n","\n","    del (\n","        train_layout_dataset,\n","        valid_layout_dataset,\n","        model,\n","        optimizer,\n","        dfscore,\n","        dflog,\n","        records,\n","    )\n","    gc.collect()\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":22,"metadata":{"tags":[]},"outputs":[{"data":{"text/html":["Finishing last run (ID:upch2uc2) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72f38d8074b2469c8e86f02ace07d051","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.004 MB of 0.007 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.561937…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">1115(テスト)ランダム</strong> at: <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/upch2uc2' target=\"_blank\">https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/upch2uc2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20231115_140739-upch2uc2/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:upch2uc2). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0004bc4c943b47358533740365576758","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113166659035617, max=1.0…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.16.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.12"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/yamaguchi/kaggle/experiments/1115/wandb/run-20231115_140757-5yyvc5z8</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/5yyvc5z8' target=\"_blank\">1115(テスト)ランダム</a></strong> to <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan' target=\"_blank\">https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/5yyvc5z8' target=\"_blank\">https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/5yyvc5z8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["学習済みモデルを読み込みます\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6fffdf7fb4c34ad2be08869729452252","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.42399 score: 0.545\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bbb37cb2de248fb8298c5554a718e5f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.42147 score: 0.556\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e8310007c2341ee896ecceb0620f02f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.41014 score: 0.574\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"388d1a2feceb4447beeaafe72671e8c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.48100 score: 0.541\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1438205c201a41b9a6bf302efcccfeab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.44789 score: 0.549\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11bee9463cc743eba127eaa3098c2e39","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.40443 score: 0.582\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cdf50456a984943ad9ae186408bee81","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.42320 score: 0.579\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20961f87d21747508072a9d626c5a7fa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.40302 score: 0.583\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4bf42a15e50c44739cbd06a8b16ef0e7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.40893 score: 0.593\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4c163b208324b368468309935c10bae","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.41135 score: 0.584\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee0ac9a908bd4d9db9c5dcf6fc983a4c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.39747 score: 0.598\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49cc0969626c4e71bc3d0208eaa0159a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.40804 score: 0.585\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e7963d00c294f1bb0d263cf1bb79c77","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.40271 score: 0.593\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"078f7c0a1cbb4006aa595171311bceaa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.39347 score: 0.602\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4ece7e25a82426980873600f3fdd4a9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.39902 score: 0.600\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bc3a0de58b9425a966c1066c26a6ec1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.39417 score: 0.604\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"847597d6bbaf4dc49acce0ede4489cea","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.39501 score: 0.606\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55d766a7f6584ca2ab01474271d85ec7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.39268 score: 0.609\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76f97135b8e2448a991f28ec706f4179","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.39685 score: 0.604\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4f7cba8418541718459cb96aada29a5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/506 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.39535 score: 0.607\n"]}],"source":["exptname = \"1115(テスト)ランダム\"\n","\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"predict-ai-model-runtime-for-sun-scan-clan\",\n","    # track hyperparameters and run metadata\n","    config={\n","        \"params\": asdict(params),\n","        \"const\": asdict(const),\n","        \"validation\": \"hold-out\",\n","    },\n","    name=exptname,\n","    tags=[\"all\"],\n",")\n","\n","seed_everything(43)\n","dftrain = dataset_dict[\"train\"]\n","dfvalid = dataset_dict[\"valid\"]\n","\n","train_model(\n","    dftrain=dftrain,\n","    dfvalid=dfvalid,\n","    params=params,\n","    const=const,\n","    cat_status=cat_status,\n","    cat_config_status=cat_config_status,\n","    savedir=workdir,\n","    checkpointdir=checkpointdir,\n",")\n","wandb.alert(title=exptname, text=f\"Train End\")"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fca44206872a417aad164fa605b98dcc","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.007 MB of 0.020 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.378970…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>i_graph</td><td>▃▆▂▆▂▇▃▆▂▆▃▇▃▆▂▇▃▇▂▆▄▇▃▆▂█▃▇▃▆▄▇▃▇▃█▄▇▃▁</td></tr><tr><td>lr</td><td>███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>num_train_log</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>num_valid_log</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train-nlp-default/epoch_loss</td><td>▅█▂▅▁▃▂▂▂▃▂▂▁▂▆▃▂▂▂▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-nlp-default/graph_loss</td><td>█▂▂▆▂▇▂▂▂▂▃▂▂▂▄▁▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂</td></tr><tr><td>train-nlp-default/score</td><td>▁▇▆▆▇▆▇▇▆▆▆▇█▇▆█▇▇▇▆▆▇█▆▇▆▆▇▇▇█▆▆▇▇▆█▇██</td></tr><tr><td>train-nlp-random/epoch_loss</td><td>█▇▇▄▂▃▃▂▂▂▂▂▁▂▆▂▂▂▂▂▁▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-nlp-random/graph_loss</td><td>▄▃▃▂▄▃█▃▄▂▃▅▁▂▃▃▂▃▃▄▃▄▃▃▃▄▃▃▁▃▂▂▃▂▂▄▂▃▃▃</td></tr><tr><td>train-nlp-random/score</td><td>▄▅▅▆▂▃▂▄▂▆▄▁▇▆▃▃▆▄▄▂▄▃▄▃▄▃▄▄█▃▆▄▃▆▆▂▆▄▂▅</td></tr><tr><td>train-xla-default/epoch_loss</td><td>▆█▂▅▂▂▃▂▁▂▁▂▁▂▄▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-xla-default/graph_loss</td><td>▁▃▁▁▄▃▃▃▂▂▂▂▁▂▂▂▂▂▁▁▁▃▁▂█▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁</td></tr><tr><td>train-xla-default/score</td><td>▇▄▇▇▆▃▃▄▇▅▆▅▇▃▄▃▅▆▇▇▇▄▇▆▁▇█▆▇▇▇▅▇▇▇███▇█</td></tr><tr><td>train-xla-random/epoch_loss</td><td>▅█▂▅▁▃▃▂▁▂▁▂▁▂▄▂▂▂▂▂▂▁▁▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-xla-random/graph_loss</td><td>▂▁▂▂▁▁▂▁▁▁▁▁▂▁▂▁▁▁▂▁█▁▁▁▂▁▄▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>train-xla-random/score</td><td>▁▇▆▄▆█▅█▆█▇█▄▆▆▇▇▆▅▇▃▇▇▇▄▇▄▇▇▆▆▆▄▇▇▆▇▇▇▆</td></tr><tr><td>train/epoch_loss</td><td>█▇█▅▂▃▃▂▃▃▁▂▂▂▃▂▁▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/graph_loss</td><td>▃▃▃▂▄▄▂▆▄▂▄▂▃█▄▂▇▂▃▂▄▁▃▅▂▄▂▄▅▃▂▂▃▇▃▃▃▂▃▄</td></tr><tr><td>train/score</td><td>▆▆▆▇▅▅▇▅▄▇▅▇▆▁▅▇▃▇▇▇▅█▆▆▇▅▇▅▄▇▇▇▆▃▇▇▇▇▆▅</td></tr><tr><td>valid-nlp-default/epoch_loss</td><td>██▄▄▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid-nlp-default/graph_loss</td><td>█▆▅▂█▃▄▂▂▂▂▂▂▅▂▅▂▄▂▅▁▄▁▄▁▄▃▃▃▃▄▄▄▃▄▃▃▄▄▄</td></tr><tr><td>valid-nlp-default/score</td><td>▂▅▃▇▃▅▄█▅█▅█▅▄▄▄▄▅▅▄▅▄▆▄▇▅▂▄▁▄▁▅▂▅▁▅▁▅▁▄</td></tr><tr><td>valid-nlp-random/epoch_loss</td><td>██▄▄▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid-nlp-random/graph_loss</td><td>█▂▅▁▆▁▄▁▃▁▃▁▃▁▃▁▂▁▃▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>valid-nlp-random/score</td><td>▁▇▃▇▃█▄▇▅▇▅▇▅█▅█▅█▅█▅█▆█▆█▇█▇█▇█▇█▇█▇█▇█</td></tr><tr><td>valid-xla-default/epoch_loss</td><td>██▄▄▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid-xla-default/graph_loss</td><td>▄█▃▆▁█▂▇▂▇▃▆▁▇▁▇▁▆▂▆▄▁▃▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▅</td></tr><tr><td>valid-xla-default/score</td><td>▇▁▇▃▇▁▇▂▇▂▇▁█▁█▂▇▃█▂▇▇▇▇▇▇▇▇█▇█▇█▇█▇█▇█▆</td></tr><tr><td>valid-xla-random/epoch_loss</td><td>██▄▄▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid-xla-random/graph_loss</td><td>▄▇▂▆▂▇▁▆▂▆▂▇▁▅▁▅▁▆▁▅▄▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂█</td></tr><tr><td>valid-xla-random/score</td><td>▆▁▆▂▇▂▇▂█▂█▄█▃█▃█▃█▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▃</td></tr><tr><td>valid/epoch_loss</td><td>██▄▄▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/graph_loss</td><td>▇▂▃▁▄▃▄▁▄▁▃█▄▂▃▁▄▁▃█▄▂▄▁▄▃▃█▄▂▄▁▄▂▃▇▂▂▄▆</td></tr><tr><td>valid/score</td><td>▄▇▆█▅▇▆█▆█▇▁▅█▆█▆█▇▂▅█▆█▆▇▇▃▅█▆█▆▇▇▃▇█▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>arch</td><td>xla</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>filename</td><td>unet_3d.4x4.bf16</td></tr><tr><td>i_graph</td><td>-1</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>num_train_log</td><td>10119</td></tr><tr><td>num_valid_log</td><td>1039</td></tr><tr><td>perm</td><td>random</td></tr><tr><td>train-nlp-default/epoch_loss</td><td>0.29205</td></tr><tr><td>train-nlp-default/graph_loss</td><td>0.3249</td></tr><tr><td>train-nlp-default/score</td><td>0.60631</td></tr><tr><td>train-nlp-random/epoch_loss</td><td>0.2918</td></tr><tr><td>train-nlp-random/graph_loss</td><td>0.2116</td></tr><tr><td>train-nlp-random/score</td><td>0.74949</td></tr><tr><td>train-xla-default/epoch_loss</td><td>0.2931</td></tr><tr><td>train-xla-default/graph_loss</td><td>0.58434</td></tr><tr><td>train-xla-default/score</td><td>0.38532</td></tr><tr><td>train-xla-random/epoch_loss</td><td>0.29223</td></tr><tr><td>train-xla-random/graph_loss</td><td>0.20874</td></tr><tr><td>train-xla-random/score</td><td>0.80311</td></tr><tr><td>train/epoch_loss</td><td>0.29205</td></tr><tr><td>train/graph_loss</td><td>0.3249</td></tr><tr><td>train/score</td><td>0.60631</td></tr><tr><td>valid-nlp-default/epoch_loss</td><td>0.29703</td></tr><tr><td>valid-nlp-default/graph_loss</td><td>0.38529</td></tr><tr><td>valid-nlp-default/score</td><td>0.56685</td></tr><tr><td>valid-nlp-random/epoch_loss</td><td>0.29703</td></tr><tr><td>valid-nlp-random/graph_loss</td><td>0.23721</td></tr><tr><td>valid-nlp-random/score</td><td>0.85615</td></tr><tr><td>valid-xla-default/epoch_loss</td><td>0.29703</td></tr><tr><td>valid-xla-default/graph_loss</td><td>0.62954</td></tr><tr><td>valid-xla-default/score</td><td>0.41727</td></tr><tr><td>valid-xla-random/epoch_loss</td><td>0.29703</td></tr><tr><td>valid-xla-random/graph_loss</td><td>0.56771</td></tr><tr><td>valid-xla-random/score</td><td>0.57581</td></tr><tr><td>valid/epoch_loss</td><td>0.29703</td></tr><tr><td>valid/graph_loss</td><td>0.56771</td></tr><tr><td>valid/score</td><td>0.57581</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">1115(テスト)</strong> at: <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/nwa8lq7g' target=\"_blank\">https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/nwa8lq7g</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20231114_224415-nwa8lq7g/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["## 推論\n"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["PosixPath('/home/yamaguchi/kaggle/experiments/1115/out/ranknet')"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["workdir"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cccbfad7a36e4242a42c31de9845336c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["savedir = workdir\n","\n","records = []\n","\n","dftest = dataset_dict[\"test\"]\n","\n","test_layout_dataset = LayoutDataset(\n","    dataset=dftest,\n","    params=params,\n","    cat_status=cat_status,\n","    cat_config_status=cat_config_status,\n",")\n","model = SimpleLayoutModel(\n","    params=params,\n","    const=const,\n","    cat_status=cat_status,\n","    cat_config_status=cat_config_status,\n",")\n","model.load_state_dict(torch.load(workdir / \"final_model.pt\"))\n","model.eval()\n","\n","with tqdm(range(len(test_layout_dataset))) as pbar:\n","    for i in pbar:\n","        file_info = test_layout_dataset.get_ith_file_info(i)\n","\n","        pred_list = []\n","        for (\n","            node_opcode,\n","            node_flag_feat,\n","            node_cont_feat,\n","            node_cat_feat,\n","            node_config_feat,\n","            node_config_cont_feat,\n","            edge_index,\n","            node_splits,\n","            node_config_ids,\n","            target,\n","        ) in test_layout_dataset.getitem_as_batch(i):\n","            pred_batch = model(\n","                node_opcode=node_opcode,\n","                node_flag_feat=node_flag_feat,\n","                node_cont_feat=node_cont_feat,\n","                node_cat_feat=node_cat_feat,\n","                node_config_feat=node_config_feat,\n","                node_config_cont_feat=node_config_cont_feat,\n","                edge_index=edge_index,\n","                node_splits=node_splits,\n","                node_config_ids=node_config_ids,\n","            )\n","            if params.device == GPU:\n","                pred_batch = pred_batch.cpu().detach().numpy()\n","            else:\n","                pred_batch = pred_batch.detach().numpy()\n","            # pred_batchは高いものほどよい\n","            pred_batch = -pred_batch\n","            pred_list.append(pred_batch)\n","\n","            del (\n","                node_opcode,\n","                node_flag_feat,\n","                node_cont_feat,\n","                node_cat_feat,\n","                node_config_feat,\n","                node_config_cont_feat,\n","                edge_index,\n","                node_splits,\n","                target,\n","            )\n","            gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        pred = np.hstack(pred_list)\n","\n","        ID = f\"layout:{file_info['arch']}:{file_info['perm']}:{file_info['filename']}\"\n","        records.append(\n","            {\"ID\": ID, \"TopConfigs\": \";\".join(list(map(str, pred.argsort())))}\n","        )\n","\n","del test_layout_dataset, model\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","dfpred = pd.DataFrame(records)\n","dfpred[[\"ID\", \"TopConfigs\"]].to_csv(savedir / f\"submission.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"environment":{"kernel":"python3","name":"pytorch-gpu.2-0.m112","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m112"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
