{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import gc\n",
    "import torch\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "import wandb\n",
    "from dataclasses import asdict\n",
    "from typing import Any\n",
    "from scipy.stats import kendalltau\n",
    "import json\n",
    "\n",
    "\n",
    "GPU = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = Path().resolve().parent.parent\n",
    "inputdir = rootdir / \"data\" / \"predict-ai-model-runtime\"\n",
    "embeddir = Path().resolve() / \"out\" / \"ranknet\" / \"embeddings\"\n",
    "workdir = Path().resolve() / \"out\" / \"finetuning-listmle-holdout\"\n",
    "workdir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {}\n",
    "\n",
    "for ds in [\"train\", \"valid\", \"test\"]:\n",
    "    records = []\n",
    "    for arch, perm in itertools.product([\"nlp\", \"xla\"], [\"default\", \"random\"]):\n",
    "        datadir = inputdir / f\"npz_all/npz/layout/{arch}/{perm}/{ds}\"\n",
    "        for filepath in sorted(datadir.glob(\"*.npz\")):\n",
    "            filename = str(filepath).split(\"/\")[-1].replace(\".npz\", \"\")\n",
    "            records.append(\n",
    "                {\n",
    "                    \"arch\": arch,\n",
    "                    \"perm\": perm,\n",
    "                    \"filename\": filename,\n",
    "                    \"filepath\": filepath,\n",
    "                    \"embed_filepath\": embeddir / arch / perm / ds / f\"{filename}.npz\",\n",
    "                }\n",
    "            )\n",
    "    dataset_dict[ds] = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in dataset_dict:\n",
    "    indexes = []\n",
    "    for i, row in dataset_dict[ds].iterrows():\n",
    "        try:\n",
    "            np.load(row[\"filepath\"])\n",
    "            np.load(row[\"embed_filepath\"])\n",
    "            indexes.append(i)\n",
    "        except FileNotFoundError as e:\n",
    "            print(row[\"embed_filepath\"])\n",
    "\n",
    "    dataset_dict[ds] = dataset_dict[ds].iloc[indexes].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_tensor(dataset, filename):\n",
    "    dataset_as_dict = {}\n",
    "    embeddings_list = []\n",
    "    for i, row in tqdm(dataset.iterrows()):\n",
    "        fileobj = np.load(row[\"filepath\"])\n",
    "        embed_fileobj = np.load(row[\"embed_filepath\"])\n",
    "        config_runtime = fileobj[\"config_runtime\"]\n",
    "        target = np.argsort(np.argsort(-config_runtime))\n",
    "        embeddings = embed_fileobj[\"embeddings\"]\n",
    "\n",
    "        dataset_as_dict[i] = {\n",
    "            \"arch\": row[\"arch\"],\n",
    "            \"perm\": row[\"perm\"],\n",
    "            \"filename\": row[\"filename\"],\n",
    "            \"target\": target,\n",
    "            \"X\": embeddings,\n",
    "        }\n",
    "        embeddings_list.append(embeddings)\n",
    "    embeddings_list = np.concatenate(embeddings_list, axis=0)\n",
    "\n",
    "    emb_scl = embeddings_list.max(axis=0) - embeddings_list.min(axis=0)\n",
    "    emb_mean = embeddings_list.mean(axis=0)\n",
    "    del embeddings_list\n",
    "\n",
    "    for i in dataset_as_dict:\n",
    "        dataset_as_dict[i][\"X\"] = (dataset_as_dict[i][\"X\"] - emb_mean) / emb_scl\n",
    "\n",
    "    with open(workdir / f\"{filename}.json\", \"w\") as f:\n",
    "        json.dump({\"xmean\": emb_mean.tolist(), \"xscl\": emb_scl.tolist()}, f, indent=4)\n",
    "    return dataset_as_dict\n",
    "\n",
    "\n",
    "def create_valid_dataset_tensor(dataset, filename):\n",
    "    dataset_as_dict = {}\n",
    "    for i, row in tqdm(dataset.iterrows()):\n",
    "        fileobj = np.load(row[\"filepath\"])\n",
    "        embed_fileobj = np.load(row[\"embed_filepath\"])\n",
    "        config_runtime = fileobj[\"config_runtime\"]\n",
    "        target = np.argsort(np.argsort(-config_runtime))\n",
    "        embeddings = embed_fileobj[\"embeddings\"]\n",
    "\n",
    "        dataset_as_dict[i] = {\n",
    "            \"arch\": row[\"arch\"],\n",
    "            \"perm\": row[\"perm\"],\n",
    "            \"filename\": row[\"filename\"],\n",
    "            \"target\": target,\n",
    "            \"X\": embeddings,\n",
    "        }\n",
    "\n",
    "    with open(workdir / f\"{filename}.json\", \"r\") as f:\n",
    "        scler = json.load(f)\n",
    "        emb_scl, emb_mean = np.array(scler[\"xscl\"]), np.array(scler[\"xmean\"])\n",
    "\n",
    "    for i in dataset_as_dict:\n",
    "        dataset_as_dict[i][\"X\"] = (dataset_as_dict[i][\"X\"] - emb_mean) / emb_scl\n",
    "\n",
    "    return dataset_as_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Params:\n",
    "    device: str\n",
    "    dims: list[int] = field(default_factory=lambda: [512, 512, 512])\n",
    "    epoch: int = 500\n",
    "    T_max: int = 500\n",
    "    eta_min: float = 1e-6\n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 0\n",
    "    grad_clip_max_norm: float = 1.0\n",
    "    grad_clip_norm_type: float = 2.0\n",
    "\n",
    "    sample_size: int = 1000\n",
    "    batch_size: int = 32\n",
    "\n",
    "    num_feats: int = 192\n",
    "\n",
    "\n",
    "params = Params(device=GPU if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class FineTuningDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_as_dict: dict[str, Any],\n",
    "        params: Params,\n",
    "    ) -> None:\n",
    "        self.dataset_as_dict = dataset_as_dict\n",
    "        self.params = params\n",
    "\n",
    "    @property\n",
    "    def device(self) -> str:\n",
    "        return self.params.device\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset_as_dict)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        dataset = self.dataset_as_dict[idx]\n",
    "        num_configs = dataset[\"target\"].shape[0]\n",
    "        indexes = random.choices(list(range(num_configs)), k=self.params.sample_size)\n",
    "\n",
    "        embeddings = torch.tensor(\n",
    "            dataset[\"X\"][indexes, :],\n",
    "            dtype=torch.float32,\n",
    "        ).to(self.device)\n",
    "        target = torch.tensor(\n",
    "            dataset[\"target\"][indexes],\n",
    "            dtype=torch.float32,\n",
    "        ).to(self.device)\n",
    "\n",
    "        return embeddings, target\n",
    "\n",
    "    def get_info(self, idx):\n",
    "        dataset = self.dataset_as_dict[idx]\n",
    "        return dataset[\"arch\"], dataset[\"perm\"], dataset[\"filename\"]\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        params: Params,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "\n",
    "        dims = [params.num_feats] + self.params.dims\n",
    "        fc_layer = []\n",
    "        for i in range(len(dims) - 1):\n",
    "            fc_layer += [\n",
    "                nn.Linear(\n",
    "                    in_features=dims[i],\n",
    "                    out_features=dims[i + 1],\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "            ]\n",
    "        fc_layer += [\n",
    "            nn.Linear(\n",
    "                in_features=dims[-1],\n",
    "                out_features=1,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        self.net = nn.Sequential(*fc_layer)\n",
    "        self.to(self.params.device)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        return self.net(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankNet(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    RankNet loss introduced in \"Learning to Rank using Gradient Descent\".\n",
    "    :param y_pred: predictions from the model, shape [batch_size, slate_length]\n",
    "    :param y_true: ground truth labels, shape [batch_size, slate_length]\n",
    "    :return: loss value, a torch.Tensor\n",
    "    \"\"\"\n",
    "    y_pred = y_pred.clone()\n",
    "    y_true = y_true.clone()\n",
    "\n",
    "    document_pairs_candidates = list(itertools.combinations(range(y_true.shape[1]), 2))\n",
    "\n",
    "    pairs_true = y_true[:, document_pairs_candidates]\n",
    "    selected_pred = y_pred[:, document_pairs_candidates]\n",
    "\n",
    "    true_diffs = pairs_true[:, :, 0] - pairs_true[:, :, 1]\n",
    "    pred_diffs = selected_pred[:, :, 0] - selected_pred[:, :, 1]\n",
    "\n",
    "    the_mask = (true_diffs > 0) & (~torch.isinf(true_diffs))\n",
    "    pred_diffs = pred_diffs[the_mask]\n",
    "\n",
    "    true_diffs = (true_diffs > 0).type(torch.float32)\n",
    "    true_diffs = true_diffs[the_mask]\n",
    "\n",
    "    return nn.BCEWithLogitsLoss()(pred_diffs, true_diffs)\n",
    "\n",
    "\n",
    "class ListMLE(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        logits: torch.Tensor\n",
    "            予測（バッチサイズ, 要素数, ）\n",
    "        labels: torch.Tensor\n",
    "            目的変数（バッチサイズ, 要素数, ）\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "        \"\"\"\n",
    "        # 正解をソート\n",
    "        labels_sorted, labels_sorted_indice = labels.sort(descending=True, dim=1)\n",
    "        # 予測を正解順でソート\n",
    "        logits_sorted_by_true = torch.gather(logits, dim=1, index=labels_sorted_indice)\n",
    "        # 予測値の最大値で予測値を引く（expの爆発予防）\n",
    "        logits_max, _ = logits_sorted_by_true.max(dim=1, keepdim=True)\n",
    "        logits_sorted_by_true = logits_sorted_by_true - logits_max\n",
    "        # ランキングが低いものから累積する(その後正解順に戻す)\n",
    "        cumsums = torch.cumsum(logits_sorted_by_true.exp().flip(dims=[1]), dim=1).flip(\n",
    "            dims=[1]\n",
    "        )\n",
    "        # 誤差\n",
    "        negative_log_likelihood = torch.sum(\n",
    "            torch.log(cumsums) - logits_sorted_by_true, dim=1\n",
    "        )\n",
    "        return torch.mean(negative_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def to_cpu_numpy(\n",
    "    params: Params, pred: torch.Tensor, truth: torch.Tensor\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    if params.device == GPU:\n",
    "        pred_ = pred.cpu().detach().numpy()\n",
    "        truth_ = truth.cpu().detach().numpy()\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        pred_ = pred.detach().numpy()\n",
    "        truth_ = truth.detach().numpy()\n",
    "    return pred_, truth_\n",
    "\n",
    "\n",
    "def train(params, train_dataset_as_dict, valid_dataset_as_dict, savedir):\n",
    "    train_dataset = FineTuningDataset(\n",
    "        dataset_as_dict=train_dataset_as_dict, params=params\n",
    "    )\n",
    "    valid_dataset = FineTuningDataset(\n",
    "        dataset_as_dict=valid_dataset_as_dict, params=params\n",
    "    )\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, batch_size=params.batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    model = MLP(params=params)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=params.lr, weight_decay=params.weight_decay\n",
    "    )\n",
    "    scheduler = CosineAnnealingLR(\n",
    "        optimizer=optimizer, T_max=params.T_max, eta_min=params.eta_min\n",
    "    )\n",
    "    criterion = ListMLE()\n",
    "\n",
    "    pbar = tqdm(range(params.epoch))\n",
    "    num_train_log, num_valid_log = 0, 0\n",
    "    for epoch in range(params.epoch):\n",
    "        model.train()\n",
    "\n",
    "        num_iters = len(train_dataloader)\n",
    "        for i_iter, (X, target) in enumerate(train_dataloader):\n",
    "            pred = model(X)\n",
    "\n",
    "            if (len(pred.shape) == 1) or (len(target.shape) == 1):\n",
    "                pred, target = pred.reshape(1, -1), target.reshape(1, -1)\n",
    "            loss = criterion(pred, target)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(\n",
    "                model.parameters(),\n",
    "                max_norm=params.grad_clip_max_norm,\n",
    "                norm_type=params.grad_clip_norm_type,\n",
    "            )\n",
    "            optimizer.step()\n",
    "            scheduler.step(epoch + i_iter / num_iters)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred, target = to_cpu_numpy(params, pred, target)\n",
    "\n",
    "            scores = []\n",
    "            for pred_, target_ in zip(pred, target):\n",
    "                score = kendalltau(target_, pred_).correlation\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"iter\": i_iter,\n",
    "                        \"lr\": scheduler.get_last_lr()[0],\n",
    "                        \"train/score\": score,\n",
    "                        \"train/loss\": loss,\n",
    "                        \"train/pred\": pred,\n",
    "                        \"train/target\": target,\n",
    "                        \"train/count\": num_train_log,\n",
    "                    }\n",
    "                )\n",
    "                num_train_log += 1\n",
    "                scores.append(score)\n",
    "            scores = np.array(scores)\n",
    "            # pbar.set_description(\n",
    "            #     f\"[{epoch + 1}] score={np.mean(scores[~np.isnan(scores)]):.3f} loss={loss.item():5f}\"\n",
    "            # )\n",
    "\n",
    "        model.eval()\n",
    "        losses, scores = [], []\n",
    "        for i_graph in range(len(valid_dataset)):\n",
    "            arch, perm, filename = valid_dataset.get_info(i_graph)\n",
    "            X, target = valid_dataset[i_graph]\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred.reshape(1, -1), target.reshape(1, -1))\n",
    "            graph_loss = loss.item()\n",
    "            pred, target = to_cpu_numpy(params, pred, target)\n",
    "            score = kendalltau(target, pred).correlation\n",
    "\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"iter\": i_iter,\n",
    "                    \"lr\": scheduler.get_last_lr()[0],\n",
    "                    \"valid/score\": score,\n",
    "                    \"valid/loss\": graph_loss,\n",
    "                    \"valid/pred\": pred,\n",
    "                    \"valid/target\": target,\n",
    "                    \"valid/count\": num_valid_log,\n",
    "                }\n",
    "            )\n",
    "            num_valid_log += 1\n",
    "            losses.append(graph_loss)\n",
    "            scores.append(score)\n",
    "        losses = np.array(losses)\n",
    "        scores = np.array(scores)\n",
    "        # print(\n",
    "        #     f\"[{epoch + 1}] valid score={np.mean(scores[~np.isnan(scores)]):.3f} valid loss={np.mean(losses[~np.isnan(losses)]):5f}\"\n",
    "        # )\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(), savedir / f\"epoch{epoch + 1}_model.pt\")\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(\n",
    "            f\"[{epoch + 1}] valid score={np.mean(scores[~np.isnan(scores)]):.3f} valid loss={np.mean(losses[~np.isnan(losses)]):5f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eedae759ea645d8b8404140d534c111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4d36890a9045498dd56baa821abf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset_as_dict = create_dataset_tensor(\n",
    "    dataset=dataset_dict[\"train\"], filename=\"scl\"\n",
    ")\n",
    "valid_dataset_as_dict = create_valid_dataset_tensor(\n",
    "    dataset=dataset_dict[\"valid\"], filename=\"scl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:pcav6zqh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4be6db263b5456d9087b1f7edca1615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter</td><td>▂▄█▁▅█▂▆▇▃▆█▄▇█▄▆▁▅▇▂▄▇▃▅█▄▅█▂▆▁▃▇█▄▇▁▅█</td></tr><tr><td>lr</td><td>██████████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>train/count</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/loss</td><td>███▇▇▇▆▆▅▅▄▅▃▄▄█▃▁▂▄▃▃▅▂▄▄▅▁▄▄▃▁▄▂▄▄▂▃▃▃</td></tr><tr><td>train/score</td><td>▆ ▂▆▇▃▅▄█▁▆▄▆▂▄▃▂█▇▃▃▇▆▇▃▄▄▅▄██▃▆▃▄▃█▂▃▅</td></tr><tr><td>valid/count</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>valid/loss</td><td>▅▅▄▄▄▅▄▃▅▄▃▄▄▅▄▄▄▄▄▅▄▃▄▄▂▄▄▁▇▄▃▅▃▄▄▃█▄▃▇</td></tr><tr><td>valid/score</td><td>▄▇▇▄▇▁▄▇▃▄▇▄▄▇▅▅▂▅▄▂▄▇▂▄▇▅▅█▅▃▇▃▇▆▄▇▇▅▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>iter</td><td>1</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>train/count</td><td>7505</td></tr><tr><td>train/loss</td><td>5323.70215</td></tr><tr><td>train/score</td><td>0.44449</td></tr><tr><td>valid/count</td><td>755</td></tr><tr><td>valid/loss</td><td>5843.60254</td></tr><tr><td>valid/score</td><td>0.4411</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">1108-勾配クリップ-ミスマッチ-listmle-finetuning-holdout</strong> at: <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/pcav6zqh' target=\"_blank\">https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/pcav6zqh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231112_224845-pcav6zqh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:pcav6zqh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e13a88bf10a4a9eb695f023fe07e696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112815162373915, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/yamaguchi/kaggle/experiments/1109-勾配クリップ-ミスマッチ/wandb/run-20231112_225002-h6bca97k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/h6bca97k' target=\"_blank\">1108-勾配クリップ-ミスマッチ-listmle-finetuning-holdout</a></strong> to <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan' target=\"_blank\">https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/h6bca97k' target=\"_blank\">https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/h6bca97k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b032aa8dcbb34f0ea1f6f4edfdd895ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamaguchi/.pyenv/versions/3.11.5/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc25ed3a00542dc982f3eba107321e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter</td><td>███▇▆▅▅▄▃▃▂▁██▇▇▆▅▅▄▄▃▂▁███▇▆▅▅▄▄▃▂▂▁██▇</td></tr><tr><td>lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/count</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/loss</td><td>█▅▅▆▅▄▅▆▅▃▄▃▂▄▄▃▂▃▅▃▄▄▃▃▄▃▄▃▃▂▃▃▁▃▃▂▂▄▄▄</td></tr><tr><td>train/score</td><td>▁▅▅▆▅█▃▄▅▇▇▆▇▆▆▄▇▃▃▃▁▅▄█▄█▇▅█▆▇█▇▄█████▅</td></tr><tr><td>valid/count</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid/loss</td><td>▆▆▅▄▆▆▄▅▆▃▇▆▅▇▆▆▇▅▆▆▇▆▅▇▆▁▇▅▂▆▇▃▅█▅▁▇▅▂▆</td></tr><tr><td>valid/score</td><td>▆▃▆▆▃▂▇▅▄█▃▄▆▄▃▃▁▅▄▃▃▄▆▃▃█▁▅▇▃▃▇▇▂▇█▁▄▇▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>499</td></tr><tr><td>iter</td><td>16</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>train/count</td><td>267499</td></tr><tr><td>train/loss</td><td>4954.85938</td></tr><tr><td>train/score</td><td>0.88406</td></tr><tr><td>valid/count</td><td>26999</td></tr><tr><td>valid/loss</td><td>5836.83008</td></tr><tr><td>valid/score</td><td>0.31367</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">1108-勾配クリップ-ミスマッチ-listmle-finetuning-holdout</strong> at: <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/h6bca97k' target=\"_blank\">https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/h6bca97k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231112_225002-h6bca97k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exptname = f\"1108-勾配クリップ-ミスマッチ-listmle-finetuning-holdout\"\n",
    "\n",
    "wandb.init(\n",
    "    project=\"predict-ai-model-runtime-for-sun-scan-clan\",\n",
    "    config={\n",
    "        \"params\": asdict(params),\n",
    "    },\n",
    "    name=exptname,\n",
    ")\n",
    "\n",
    "seed_everything(43)\n",
    "\n",
    "savedir = workdir\n",
    "savedir.mkdir(exist_ok=True, parents=True)\n",
    "train(\n",
    "    params=params,\n",
    "    train_dataset_as_dict=train_dataset_as_dict,\n",
    "    valid_dataset_as_dict=valid_dataset_as_dict,\n",
    "    savedir=savedir,\n",
    ")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
