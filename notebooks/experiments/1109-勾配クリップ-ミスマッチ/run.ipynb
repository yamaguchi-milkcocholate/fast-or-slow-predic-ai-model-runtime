{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T00:26:05.651677Z","iopub.status.busy":"2023-11-09T00:26:05.651285Z","iopub.status.idle":"2023-11-09T00:26:13.665905Z","shell.execute_reply":"2023-11-09T00:26:13.664684Z","shell.execute_reply.started":"2023-11-09T00:26:05.651641Z"},"tags":[],"trusted":true},"outputs":[],"source":["import pickle\n","import numpy as np\n","import pandas as pd\n","import warnings\n","import itertools\n","import random\n","import gc\n","import torch\n","import os\n","from copy import deepcopy\n","from torch import nn\n","from torch.utils.data import Dataset\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torch_geometric.nn import GCNConv, Sequential\n","from tqdm.notebook import tqdm\n","from pathlib import Path\n","from dataclasses import dataclass, field\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","import wandb\n","from dataclasses import asdict\n","\n","sns.set()\n","\n","warnings.simplefilter(\"ignore\")\n","\n","GPU = \"cuda:0\""]},{"cell_type":"markdown","metadata":{},"source":["## データセットを準備\n"]},{"cell_type":"code","execution_count":2,"metadata":{"tags":[]},"outputs":[],"source":["rootdir = Path().resolve().parent.parent\n","inputdir = rootdir / \"data\" / \"predict-ai-model-runtime\"\n","node_feat_dir = rootdir / \"data\" / \"google-slow-vs-fastlayout7-85-dataset\"\n","trans_node_feat_dir = rootdir / \"data\" / \"google-slow-vs-fastlayout6-92-dataset\"\n","trans_node_config_feat_dir = rootdir / \"data\" / \"google-slow-vs-fastlayout7-81-dataset\"\n","workdir = Path().resolve() / \"out\" / \"ranknet\"\n","workdir.mkdir(exist_ok=True, parents=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"tags":[]},"outputs":[],"source":["dataset_dict = {}\n","ignores = []\n","for ds in [\"train\", \"valid\", \"test\"]:\n","    records = []\n","    for arch, perm in itertools.product([\"nlp\", \"xla\"], [\"default\", \"random\"]):\n","        datadir = inputdir / f\"npz_all/npz/layout/{arch}/{perm}/{ds}\"\n","        for filepath in sorted(datadir.glob(\"*.npz\")):\n","            filename = str(filepath).split(\"/\")[-1].replace(\".npz\", \"\")\n","\n","            if (ds != \"test\") and ((\"mlperf\" in filename) or (\"openai\" in filename)):\n","                ignores.append(filepath)\n","                continue\n","            records.append(\n","                {\n","                    \"arch\": arch,\n","                    \"perm\": perm,\n","                    \"filename\": filename,\n","                    \"filepath\": filepath,\n","                    \"node_feat_filepath\": str(\n","                        node_feat_dir / arch / perm / ds / f\"{filename}.npz\"\n","                    ),\n","                    \"trans_node_feat_filepath\": str(\n","                        trans_node_feat_dir\n","                        / \"layout\"\n","                        / arch\n","                        / perm\n","                        / ds\n","                        / f\"{filename}.npz\"\n","                    ),\n","                    \"trans_node_config_filepath\": str(\n","                        trans_node_config_feat_dir\n","                        / arch\n","                        / perm\n","                        / ds\n","                        / f\"{filename}.npz\"\n","                    ),\n","                }\n","            )\n","    dataset_dict[ds] = pd.DataFrame(records)"]},{"cell_type":"code","execution_count":4,"metadata":{"tags":[]},"outputs":[],"source":["# for filepath in tqdm(ignores):\n","#     node_config_feat = np.load(filepath)[\"node_config_feat\"]\n","\n","#     for i in range(1, node_config_feat.shape[0]):\n","#         if not (node_config_feat[0] == node_config_feat[i]).all():\n","#             filepath\n","#             break"]},{"cell_type":"code","execution_count":5,"metadata":{"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>number</th>\n","      <th>num_dims</th>\n","      <th>num_cats</th>\n","      <th>cats</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>19</td>\n","      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>68</td>\n","      <td>6</td>\n","      <td>[0, 1, 2, 3, 4, 5]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   number  num_dims  num_cats  \\\n","0       0         1        19   \n","1       1        68         6   \n","\n","                                                cats  \n","0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n","1                                 [0, 1, 2, 3, 4, 5]  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["dfcat = pd.DataFrame(\n","    [\n","        {\"number\": 0, \"num_dims\": 1, \"num_cats\": 19, \"cats\": list(range(19))},\n","        {\"number\": 1, \"num_dims\": 54 + 14, \"num_cats\": 6, \"cats\": list(range(6))},\n","    ]\n",")\n","dfcat.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>number</th>\n","      <th>num_dims</th>\n","      <th>num_cats</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   number  num_dims  num_cats\n","0       0        18         8"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dfcat_config = pd.DataFrame(\n","    [\n","        {\n","            \"number\": 0,\n","            \"num_dims\": 18,\n","            \"num_cats\": 8,\n","        },  # output_layout, input_layout, kernel_layout\n","    ]\n",")\n","dfcat_config"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["num_nodes = {}\n","for ds in dataset_dict:\n","    num_nodes[ds] = []\n","    for i, row in dataset_dict[ds].iterrows():\n","        fileobj = np.load(row[\"filepath\"])\n","        np.load(row[\"node_feat_filepath\"])\n","        np.load(row[\"trans_node_feat_filepath\"])\n","        np.load(row[\"trans_node_config_filepath\"])\n","        num_nodes[ds].append(fileobj[\"node_opcode\"].shape[0])"]},{"cell_type":"markdown","metadata":{},"source":["# データクラスを定義\n"]},{"cell_type":"code","execution_count":8,"metadata":{"tags":[]},"outputs":[],"source":["@dataclass\n","class CatStatus:\n","    dfcat: pd.DataFrame\n","    prefix: str\n","    num_cat_dict: dict[str, int] = field(init=False)\n","    index_dict: dict[str, list[int]] = field(init=False)\n","\n","    def __post_init__(self) -> None:\n","        self.num_cat_dict, self.index_dict = {}, {}\n","        dim_start = 0\n","        for i, row in self.dfcat.iterrows():\n","            self.num_cat_dict[f\"{self.prefix}cat_feat{i + 1}\"] = row[\"num_cats\"]\n","            self.index_dict[f\"{self.prefix}cat_feat{i + 1}\"] = list(\n","                range(dim_start, dim_start + row[\"num_dims\"])\n","            )\n","            dim_start += row[\"num_dims\"]\n","\n","\n","cat_status = CatStatus(dfcat=dfcat, prefix=\"\")\n","cat_config_status = CatStatus(dfcat=dfcat_config, prefix=\"config_\")\n","\n","\n","@dataclass\n","class Const:\n","    num_node_flag_feat_dim: int\n","    num_node_cont_feat_dim: int\n","    num_node_cat_feat_dim: int\n","    num_node_config_cont_feat_dim: int\n","\n","    # 演算子の種類\n","    num_operations: int = 120\n","    # 各configの次元数\n","    num_config_dims: int = 6\n","\n","\n","fileobj = np.load(dataset_dict[\"train\"].iloc[0][\"node_feat_filepath\"])\n","trans_fileobj = np.load(dataset_dict[\"train\"].iloc[0][\"trans_node_feat_filepath\"])\n","trans_config_fileobj = np.load(\n","    dataset_dict[\"train\"].iloc[0][\"trans_node_config_filepath\"]\n",")\n","\n","node_flag_feat, node_cont_feat = fileobj[\"node_flag_feat\"], fileobj[\"node_cont_feat\"]\n","node_enum_feat, node_dimension_number_feat = (\n","    fileobj[\"node_enum_feat\"],\n","    fileobj[\"node_dimension_number_feat\"],\n",")\n","trans_node_cont_feat, trans_node_cat_feat = (\n","    trans_fileobj[\"node_cont_feat\"],\n","    trans_fileobj[\"node_cat_feat\"],\n",")\n","trans_node_config_cont_feat = trans_config_fileobj[\"node_config_cont_feat\"]\n","const = Const(\n","    num_node_flag_feat_dim=node_flag_feat.shape[1] + 1,  # config_idsの分+1\n","    num_node_cont_feat_dim=node_cont_feat.shape[1] + trans_node_cont_feat.shape[1],\n","    num_node_cat_feat_dim=node_enum_feat.shape[1]\n","    + node_dimension_number_feat.shape[1]\n","    + trans_node_cat_feat.shape[1],\n","    num_node_config_cont_feat_dim=trans_node_config_cont_feat.shape[2],\n",")\n","\n","\n","@dataclass\n","class NodeFeatExtractor:\n","    dims: list[int] = field(default_factory=lambda: [64, 64])\n","    leakyrelu_negative_slope: float = 0.1\n","    dropout_p: float = 0.2\n","\n","\n","@dataclass\n","class GNNExtractor:\n","    dims: list[int] = field(default_factory=lambda: [64, 64])\n","    leakyrelu_negative_slope = 0.1\n","    dropout_p: float = 0.2\n","\n","\n","@dataclass\n","class CatEmbedding:\n","    num_cat: int\n","    embedding_dim: int\n","\n","\n","@dataclass\n","class Params:\n","    device: str\n","    cat_embeddings: dict[str, CatEmbedding]\n","    random_batch_size: int = 30\n","    batch_size: int = 30\n","    node_feat_extractor: NodeFeatExtractor = field(\n","        default_factory=lambda: NodeFeatExtractor()\n","    )\n","    node_config_feat_extractor: NodeFeatExtractor = field(\n","        default_factory=lambda: NodeFeatExtractor()\n","    )\n","    gnn_extractor: GNNExtractor = field(default_factory=lambda: GNNExtractor())\n","    subgraph_extractor: NodeFeatExtractor = field(\n","        default_factory=lambda: NodeFeatExtractor()\n","    )\n","    epoch: int = 20\n","    T_max: int = 20\n","    eta_min: float = 1e-5\n","    lr: float = 1e-3\n","    weight_decay: float = 0\n","    grad_clip_max_norm: float = 1.0\n","    grad_clip_norm_type: float = 2.0\n","\n","\n","cat_embeddings = {}\n","cat_embeddings.update(\n","    {\"op\": CatEmbedding(num_cat=const.num_operations, embedding_dim=16)}\n",")\n","cat_embeddings.update(\n","    {\n","        k: CatEmbedding(num_cat=v, embedding_dim=16)\n","        for k, v in cat_status.num_cat_dict.items()\n","    }\n",")\n","cat_embeddings.update(\n","    {\n","        k: CatEmbedding(num_cat=v, embedding_dim=16)\n","        for k, v in cat_config_status.num_cat_dict.items()\n","    }\n",")\n","params = Params(\n","    device=GPU if torch.cuda.is_available() else \"cpu\",\n","    cat_embeddings=cat_embeddings,\n",")\n","\n","\n","@dataclass\n","class LayoutConfigs:\n","    \"\"\"\n","    Attributes\n","    ----------\n","    node_cont_feat: np.ndarray\n","        ノード特徴量、(ノード数, 108)\n","\n","    node_cat_feat: np.ndarray\n","        ノード特徴量、(ノード数, 3)\n","\n","    node_opcode: np.ndarray\n","        ノード演算子、(ノード数,)\n","    edge_index: np.ndarray\n","        エッジ、(エッジ数, 2)\n","\n","    node_config_feat: np.ndarray\n","        設定毎のノード特徴量、(設定数, 設定可能なノード数, 3)\n","\n","    node_config_ids: np.ndarray\n","        設定可能なノードのIndex、(設定可能なノード数,)\n","    config_runtime: np.ndarray\n","        実行時間、(設定数,)\n","    node_splits: np.ndarray\n","        同じパーティションでの計算を意味する。今回は使用しない。(パーティション数, 2)\n","    \"\"\"\n","\n","    node_flag_feat: np.ndarray\n","    node_cont_feat: np.ndarray\n","    node_cat_feat: np.ndarray\n","    node_opcode: np.ndarray\n","    edge_index: np.ndarray\n","    node_config_feat: np.ndarray\n","    node_config_cont_feat: np.ndarray\n","    node_config_ids: np.ndarray\n","    config_runtime: np.ndarray\n","    node_splits: np.ndarray\n","\n","    cat_status: CatStatus\n","    cat_config_status: CatStatus\n","    target: np.ndarray = field(init=False)\n","    argsorted_indexs: list[int] = field(init=False)\n","\n","    NUM_SAMPLES: int = 1000\n","\n","    def __post_init__(self) -> None:\n","        # 設定が存在するノードのフラグ\n","        node_active_feat = np.zeros((self.num_nodes, 1))\n","        node_active_feat[self.node_config_ids, :] = 1\n","        self.node_flag_feat = np.concatenate(\n","            [self.node_flag_feat, node_active_feat], axis=1\n","        )\n","        self.node_cont_feat = self.apply_normalization(x=self.node_cont_feat)\n","        self.node_config_feat = self.node_config_feat + 1  # カテゴリは0~7にする\n","        self.node_splits = np.array(\n","            [\n","                [self.node_splits[0][i], self.node_splits[0][i + 1] - 1]\n","                for i in range(self.node_splits.shape[1] - 1)\n","            ]\n","        )\n","        self.target = self.apply_target_normalization(x=self.config_runtime)\n","        self.argsorted_indexs = np.argsort(self.config_runtime).tolist()\n","\n","    @property\n","    def num_nodes(self) -> int:\n","        \"\"\"ノード数\"\"\"\n","        return self.node_cont_feat.shape[0]\n","\n","    def get_random_config_idxs(self) -> list[int]:\n","        \"\"\"tpu_graphのサンプリング方法\n","        https://github.com/google-research-datasets/tpu_graphs/blob/main/tpu_graphs/baselines/layout/data.py#L352\n","        \"\"\"\n","        num_configs = self.config_runtime.shape[0]\n","        num_samples = min(self.NUM_SAMPLES, num_configs)\n","        third = num_samples // 3\n","\n","        middle_samples = np.random.choice(\n","            self.argsorted_indexs[third:-third], num_samples - 2 * third\n","        ).tolist()\n","        samples = (\n","            self.argsorted_indexs[:third]\n","            + self.argsorted_indexs[-third:]\n","            + middle_samples\n","        )\n","        samples = random.sample(samples, len(samples))\n","\n","        return samples\n","\n","    def get_filled_node_config_feat(\n","        self, index_list: list[int]\n","    ) -> tuple[np.ndarray, np.ndarray]:\n","        \"\"\"指定された設定の設定毎のノード特徴量を取得する。設定がない場合は補完する。\n","        Parameters\n","        ----------\n","        index_list: list[int]\n","            設定のIndex\n","\n","        Returns\n","        -------\n","        np.ndarray [(len(index_list),ノード数, 18), (len(index_list),ノード数, 連続次元数)]\n","        \"\"\"\n","        # (サンプル数, ノード数) x 3\n","        node_config_feat = np.full(\n","            (len(index_list), self.num_nodes, Const.num_config_dims * 3),\n","            Const.num_config_dims + 1,\n","        )\n","        node_config_feat[:, self.node_config_ids] = self.node_config_feat[\n","            index_list, :, :\n","        ]\n","\n","        node_config_cont_feat = np.zeros(\n","            (len(index_list), self.num_nodes, self.node_config_cont_feat.shape[2])\n","        )\n","        node_config_cont_feat[:, self.node_config_ids] = self.node_config_cont_feat[\n","            index_list, :, :\n","        ]\n","        return node_config_feat, node_config_cont_feat\n","\n","    def get_target(self, index_list: list[int]) -> np.ndarray:\n","        \"\"\"指定された設定の目的変数を取得する\n","\n","        Parameters\n","        ----------\n","        index_list: list[int]\n","            設定のIndex\n","\n","        Returns\n","        -------\n","        np.ndarray\n","        \"\"\"\n","        return self.apply_target_ranking(x=self.config_runtime[index_list])\n","\n","    def apply_normalization(self, x: np.ndarray) -> np.ndarray:\n","        \"\"\"特徴量の正規化\n","\n","        Parameters\n","        ----------\n","        x: np.ndarray\n","            2次元行列\n","\n","        Returns\n","        -------\n","        x: np.ndarray\n","            行方向に正規化された行列\n","        \"\"\"\n","        x /= 128\n","        x = np.where(x >= 0, np.log1p(x / 128), -np.log1p(-x / 128))\n","        return x\n","\n","    def apply_target_normalization(self, x: np.ndarray) -> np.ndarray:\n","        \"\"\"目的変数の正規化\n","\n","        Parameters\n","        ----------\n","        x: np.ndarray\n","            ベクトル\n","\n","        Returns\n","        -------\n","        x: np.ndarray\n","            正規化されたベクトル\n","        \"\"\"\n","        return np.log(x / x.min())\n","\n","    def apply_target_ranking(self, x: np.ndarray) -> np.ndarray:\n","        \"\"\"降順でランキング\"\"\"\n","        return np.argsort(np.argsort(-x))"]},{"cell_type":"markdown","metadata":{},"source":["## データセットを定義\n"]},{"cell_type":"code","execution_count":9,"metadata":{"tags":[]},"outputs":[],"source":["class LayoutDataset(Dataset):\n","    \"\"\"\n","    Attributes\n","    ----------\n","    rows: list[dict[str, np.ndarray]]\n","        設定をリストでもつ\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        dataset: pd.DataFrame,\n","        params: Params,\n","        cat_status: CatStatus,\n","        cat_config_status: CatStatus,\n","    ) -> None:\n","        self.rows = dataset.to_dict(\"records\")\n","        self.params = params\n","        self.cat_status = cat_status\n","        self.cat_config_status = cat_config_status\n","        self.cache_idx = None\n","        self.cache_filepath = None\n","\n","    @property\n","    def device(self) -> str:\n","        return self.params.device\n","\n","    def __len__(self) -> int:\n","        return len(self.rows)\n","\n","    def create_layout_config(self, idx: int) -> LayoutConfigs:\n","        if self.cache_idx != idx:\n","            self.cache_idx = idx\n","            fileobj = np.load(self.rows[self.cache_idx][\"filepath\"])\n","            node_feat_fileobj = np.load(self.rows[self.cache_idx][\"node_feat_filepath\"])\n","            trans_feat_fileobj = np.load(\n","                self.rows[self.cache_idx][\"trans_node_feat_filepath\"]\n","            )\n","            trans_config_feat_fileobj = np.load(\n","                self.rows[self.cache_idx][\"trans_node_config_filepath\"]\n","            )\n","\n","            node_cont_feat = np.concatenate(\n","                [\n","                    node_feat_fileobj[\"node_cont_feat\"],\n","                    trans_feat_fileobj[\"node_cont_feat\"],\n","                ],\n","                axis=1,\n","            )\n","\n","            node_cat_feat = np.concatenate(\n","                [\n","                    node_feat_fileobj[\"node_enum_feat\"],\n","                    node_feat_fileobj[\"node_dimension_number_feat\"],\n","                    trans_feat_fileobj[\"node_cat_feat\"],\n","                ],\n","                axis=1,\n","            )\n","\n","            self.cache_layout_config = LayoutConfigs(\n","                node_opcode=fileobj[\"node_opcode\"],\n","                edge_index=fileobj[\"edge_index\"],\n","                node_config_ids=fileobj[\"node_config_ids\"],\n","                config_runtime=fileobj[\"config_runtime\"],\n","                node_splits=fileobj[\"node_splits\"],\n","                node_flag_feat=node_feat_fileobj[\"node_flag_feat\"],\n","                node_cont_feat=node_cont_feat,\n","                node_cat_feat=node_cat_feat,\n","                node_config_feat=fileobj[\"node_config_feat\"],\n","                node_config_cont_feat=trans_config_feat_fileobj[\n","                    \"node_config_cont_feat\"\n","                ],\n","                cat_status=self.cat_status,\n","                cat_config_status=self.cat_config_status,\n","            )\n","        return self.cache_layout_config\n","\n","    def __getitem__(\n","        self, idx: int\n","    ) -> tuple[\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","    ]:\n","        raise NotImplementedError()\n","\n","    def getitem_as_random_batch(\n","        self, idx: int\n","    ) -> list[\n","        tuple[\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","        ]\n","    ]:\n","        layout_configs = self.create_layout_config(idx=idx)\n","\n","        index_list = layout_configs.get_random_config_idxs()\n","        for i_chunk in range(0, len(index_list), self.params.random_batch_size):\n","            chunk_index_list = index_list[\n","                i_chunk : i_chunk + self.params.random_batch_size\n","            ]\n","            yield self._get_tensors(\n","                layout_configs=layout_configs, index_list=chunk_index_list\n","            )\n","\n","    def getitem_as_batch(\n","        self, idx: int\n","    ) -> list[\n","        tuple[\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","            torch.Tensor,\n","        ]\n","    ]:\n","        \"\"\"設定をバッチで取得する\"\"\"\n","        layout_configs = self.create_layout_config(idx=idx)\n","\n","        index_list = list(range(layout_configs.config_runtime.shape[0]))\n","        for i_chunk in range(0, len(index_list), self.params.batch_size):\n","            chunk_index_list = index_list[i_chunk : i_chunk + self.params.batch_size]\n","            yield self._get_tensors(\n","                layout_configs=layout_configs, index_list=chunk_index_list\n","            )\n","\n","    def _get_tensors(\n","        self, layout_configs: LayoutConfigs, index_list: list[int]\n","    ) -> tuple[\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","        torch.Tensor,\n","    ]:\n","        \"\"\"渡された設定のIndexのテンソルを取得する\n","\n","        Parameters\n","        ----------\n","        layout_configs: LayoutConfigs\n","            Layoutのデータクラス\n","        index_list: list[int]\n","            設定のインデックス\n","\n","        Returns\n","        -------\n","        torch.Tensor\n","            ノード特徴量(フラグ)\n","        torch.Tensor\n","            ノード特徴量(連続)\n","        dict[str, torch.Tensor]\n","            ノード特徴量(カテゴリ)\n","        torch.Tensor\n","            設定毎のノード特徴量\n","        torch.Tensor\n","            設定毎のノード特徴量(連続)\n","        torch.Tensor\n","            ノード演算子\n","        torch.Tensor\n","            エッジ\n","        torch.Tensor\n","            目的変数\n","        \"\"\"\n","        # ノード特徴量(フラグ)\n","        node_flag_feat = torch.tensor(\n","            layout_configs.node_flag_feat,\n","            dtype=torch.float32,\n","        ).to(self.device)\n","        # ノード特徴量(連続)\n","        node_cont_feat = torch.tensor(\n","            layout_configs.node_cont_feat,\n","            dtype=torch.float32,\n","        ).to(self.device)\n","        # ノード特徴量(カテゴリ)\n","        node_cat_feat = torch.tensor(\n","            layout_configs.node_cat_feat,\n","            dtype=torch.int64,\n","        ).to(self.device)\n","        # 設定毎のノード特徴量(カテゴリ)\n","        (\n","            node_config_feat,\n","            node_config_cont_feat,\n","        ) = layout_configs.get_filled_node_config_feat(index_list=index_list)\n","        node_config_feat = torch.tensor(node_config_feat, dtype=torch.int64).to(\n","            self.device\n","        )\n","        node_config_cont_feat = torch.tensor(\n","            node_config_cont_feat, dtype=torch.float32\n","        ).to(self.device)\n","        # ノード演算子\n","        node_opcode = torch.tensor(layout_configs.node_opcode, dtype=torch.int64).to(\n","            self.device\n","        )\n","        # エッジ\n","        edge_index = torch.tensor(\n","            np.swapaxes(layout_configs.edge_index, 0, 1), dtype=torch.int64\n","        ).to(self.device)\n","        # サブグラフ\n","        node_splits = torch.tensor(layout_configs.node_splits, dtype=torch.int64).to(\n","            self.device\n","        )\n","        # ターゲット\n","        target = torch.tensor(\n","            layout_configs.get_target(index_list=index_list),\n","            dtype=torch.float32,\n","        ).to(self.device)\n","\n","        return (\n","            node_opcode,\n","            node_flag_feat,\n","            node_cont_feat,\n","            node_cat_feat,\n","            node_config_feat,\n","            node_config_cont_feat,\n","            edge_index,\n","            node_splits,\n","            target,\n","        )\n","\n","    def get_ith_file_info(self, i: int) -> dict[str, str]:\n","        row = self.rows[i]\n","        return {\n","            \"arch\": row[\"arch\"],\n","            \"perm\": row[\"perm\"],\n","            \"filename\": row[\"filename\"],\n","        }\n","\n","    def get_ith_runtime(self, i: int) -> np.ndarray:\n","        layout_configs = self.create_layout_config(idx=i)\n","        return layout_configs.config_runtime"]},{"cell_type":"markdown","metadata":{},"source":["## モデルを定義\n"]},{"cell_type":"code","execution_count":10,"metadata":{"tags":[]},"outputs":[],"source":["from torch_geometric.nn import MessagePassing\n","\n","\n","class EdgeConv(MessagePassing):\n","    \"\"\"\n","    ノード特徴 + 隣接ノード特徴 + 隣接ノード特徴の一致\n","    参考： https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_gnn.html#implementing-the-edge-convolution\n","    補足: 集約関数はデフォルトでdim(axis) = -2。つまりノード方向で集約するので気にしなくてOK\n","    https://github.com/pyg-team/pytorch_geometric/blob/1e12d41c28b1fb9793f17646b018071b508864d7/torch_geometric/nn/aggr/basic.py#L38\n","    \"\"\"\n","\n","    def __init__(\n","        self, x_input_dim: int, x_output_dim: int, mismatch_dim: int, dropout_p: float\n","    ):\n","        # \"Add\" aggregation\n","        super().__init__(aggr=\"max\")\n","        self.mlp = nn.Sequential(\n","            # nn.LayerNorm(x_input_dim * 2),\n","            nn.Linear(x_input_dim * 2 + mismatch_dim * 2, x_output_dim),\n","            # nn.Dropout(dropout_p),\n","            nn.ReLU(),\n","            # nn.LayerNorm(x_output_dim),\n","            nn.Linear(x_output_dim, x_output_dim),\n","            # nn.Dropout(dropout_p),\n","        )\n","\n","    def forward(self, x, x_output_layout, x_input_layout, edge_index):\n","        # x has shape [設定数, N, in_channels]\n","        # edge_index has shape [2, E]\n","        return self.propagate(\n","            edge_index,\n","            x=x,\n","            x_output_layout=x_output_layout,\n","            x_input_layout=x_input_layout,\n","        )\n","\n","    def message(\n","        self,\n","        x_i,\n","        x_j,\n","        x_output_layout_i,\n","        x_output_layout_j,\n","        x_input_layout_i,\n","        x_input_layout_j,\n","    ):\n","        \"\"\"propagate()で渡された引数xから自動でx_i, x_jノードを取り出して随時処理を実装する関数\"\"\"\n","        # x_i has shape [設定数, エッジ数, in_channels]\n","        # x_j has shape [設定数, エッジ数, in_channels]\n","        x_mismatch = torch.concat(\n","            [\n","                x_output_layout_i - x_input_layout_j,\n","                x_output_layout_j - x_input_layout_i,\n","            ],\n","            axis=2,\n","        )\n","        x_cat = torch.cat(\n","            [x_i, x_i - x_j, x_mismatch], dim=2\n","        )  # tmp has shape [設定数, エッジ数, 2 * in_channels]\n","        return self.mlp(x_cat)\n","\n","\n","class SimpleLayoutModel(torch.nn.Module):\n","    \"\"\"\n","\n","    Attributes\n","    ----------\n","    params: Params\n","        実験設定のデータクラス\n","    node_embeddings: torch.Tensor\n","        カテゴリ変数の埋め込み表現(ノード毎)\n","    node_config_embeddings: torch.Tensor\n","        カテゴリ変数の埋め込み表現(設定xノード毎)\n","    node_feat_extractor: torch.nn.Module\n","        ノードの特徴量を抽出するネットワーク\n","    gnn_extractor: torch.nn.Module\n","        グラフの特徴量を抽出するネットワーク\n","    gc: torch.nn.Module\n","        最終層の全結合層\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        params: Params,\n","        const: Const,\n","        cat_status: CatStatus,\n","        cat_config_status: CatStatus,\n","    ) -> None:\n","        super().__init__()\n","        self.params = params\n","        self.cat_status = cat_status\n","        self.cat_config_status = cat_config_status\n","\n","        # カテゴリ変数の埋め込み表現\n","        self.embeddings = nn.ModuleDict(\n","            {\n","                k: torch.nn.Embedding(v.num_cat, v.embedding_dim)\n","                for k, v in self.params.cat_embeddings.items()\n","            }\n","        )\n","\n","        # node_featのfeature_extractorを定義\n","        num_node_feat_extractor_input_dim = (\n","            const.num_node_flag_feat_dim\n","            + const.num_node_cont_feat_dim\n","            + self.num_node_feat_embedding_dims\n","        )\n","\n","        node_feat_extractor_layer = []\n","        node_feat_extractor_dims = [\n","            num_node_feat_extractor_input_dim\n","        ] + self.params.node_feat_extractor.dims\n","        for i in range(len(node_feat_extractor_dims) - 1):\n","            node_feat_extractor_layer += [\n","                # nn.LayerNorm(node_feat_extractor_dims[i]),\n","                nn.Linear(\n","                    in_features=node_feat_extractor_dims[i],\n","                    out_features=node_feat_extractor_dims[i + 1],\n","                ),\n","                # nn.Dropout(params.node_feat_extractor.dropout_p),\n","                nn.LeakyReLU(params.node_feat_extractor.leakyrelu_negative_slope),\n","            ]\n","            self.node_feat_extractor = nn.Sequential(*node_feat_extractor_layer)\n","\n","        # node_config_featのfeature_extractorを定義\n","        num_node_config_feat_extractor_input_dim = (\n","            self.num_node_config_feat_embedding_dims\n","            + const.num_node_config_cont_feat_dim\n","        )\n","\n","        node_config_feat_extractor_layer = []\n","        node_config_feat_extractor_dims = [\n","            num_node_config_feat_extractor_input_dim\n","        ] + self.params.node_config_feat_extractor.dims\n","        for i in range(len(node_feat_extractor_dims) - 1):\n","            node_config_feat_extractor_layer += [\n","                # nn.LayerNorm(node_config_feat_extractor_dims[i]),\n","                nn.Linear(\n","                    in_features=node_config_feat_extractor_dims[i],\n","                    out_features=node_config_feat_extractor_dims[i + 1],\n","                ),\n","                # nn.Dropout(params.node_config_feat_extractor.dropout_p),\n","                nn.LeakyReLU(\n","                    params.node_config_feat_extractor.leakyrelu_negative_slope\n","                ),\n","            ]\n","        self.node_config_feat_extractor = nn.Sequential(\n","            *node_config_feat_extractor_layer\n","        )\n","\n","        # ノード間のfeature_extractorの定義\n","        num_gnn_extractor_input_dim = (\n","            node_feat_extractor_dims[-1] + node_config_feat_extractor_dims[-1]\n","        )\n","\n","        gnn_extractor_layer = []\n","        gnn_extractor_dims = [\n","            num_gnn_extractor_input_dim\n","        ] + self.params.gnn_extractor.dims\n","        for i in range(len(gnn_extractor_dims) - 1):\n","            gnn_extractor_layer += [\n","                (\n","                    EdgeConv(\n","                        x_input_dim=gnn_extractor_dims[i],\n","                        x_output_dim=gnn_extractor_dims[i + 1],\n","                        # 埋め込み次元 x 6カテゴリ数 x 2種類 x 2パターン\n","                        mismatch_dim=(\n","                            self.params.cat_embeddings[\"config_cat_feat1\"].embedding_dim\n","                            * const.num_config_dims\n","                            * 2\n","                        ),\n","                        dropout_p=params.gnn_extractor.dropout_p,\n","                    ),\n","                    \"x, x_output_layout, x_input_layout, edge_index -> x\",\n","                ),\n","                nn.LeakyReLU(params.gnn_extractor.leakyrelu_negative_slope),\n","            ]\n","        self.gnn_extractor = Sequential(\n","            \"x, x_output_layout, x_input_layout, edge_index\", gnn_extractor_layer\n","        )\n","\n","        # # サブグラフのfeature_extractorの定義\n","        # num_subgraph_extractor_input_dim = (\n","        #     self.params.gnn_extractor.dims[-1] + num_gnn_extractor_input_dim\n","        # )\n","\n","        # subgraph_extractor_layer = []\n","        # subgraph_extractor_dims = [\n","        #     num_subgraph_extractor_input_dim\n","        # ] + self.params.node_feat_extractor.dims\n","        # for i in range(len(subgraph_extractor_dims) - 1):\n","        #     subgraph_extractor_layer += [\n","        #         # nn.LayerNorm(subgraph_extractor_dims[i]),\n","        #         nn.Linear(\n","        #             in_features=subgraph_extractor_dims[i],\n","        #             out_features=subgraph_extractor_dims[i + 1],\n","        #         ),\n","        #         # nn.Dropout(params.subgraph_extractor.dropout_p),\n","        #         nn.LeakyReLU(params.subgraph_extractor.leakyrelu_negative_slope),\n","        #     ]\n","        # self.subgraph_extractor = nn.Sequential(*subgraph_extractor_layer)\n","\n","        fc_layer = [\n","            # nn.LayerNorm(subgraph_extractor_dims[-1]),\n","            # nn.Linear(in_features=subgraph_extractor_dims[-1], out_features=1),\n","            nn.Linear(\n","                in_features=self.params.gnn_extractor.dims[-1]\n","                + num_gnn_extractor_input_dim,\n","                out_features=1,\n","            ),\n","        ]\n","        self.fc = nn.Sequential(*fc_layer)\n","        self.to(self.params.device)\n","\n","    @property\n","    def num_node_feat_embedding_dims(self) -> int:\n","        num_embedding_dims = 0\n","        num_embedding_dims += 1 * self.params.cat_embeddings[\"op\"].embedding_dim\n","        for cat_name, cat_index in self.cat_status.index_dict.items():\n","            num_embedding_dims += (\n","                len(cat_index) * self.params.cat_embeddings[cat_name].embedding_dim\n","            )\n","        return num_embedding_dims\n","\n","    @property\n","    def num_node_config_feat_embedding_dims(self) -> int:\n","        num_embedding_dims = 0\n","        for cat_name, cat_index in self.cat_config_status.index_dict.items():\n","            num_embedding_dims += (\n","                len(cat_index) * self.params.cat_embeddings[cat_name].embedding_dim\n","            )\n","        return num_embedding_dims\n","\n","    def forward(\n","        self,\n","        node_opcode: torch.Tensor,\n","        node_flag_feat: torch.Tensor,\n","        node_cont_feat: torch.Tensor,\n","        node_cat_feat: torch.Tensor,\n","        node_config_feat: torch.Tensor,\n","        node_config_cont_feat: torch.Tensor,\n","        edge_index: torch.Tensor,\n","        node_splits: torch.Tensor,\n","    ) -> torch.Tensor:\n","        \"\"\"\n","        Parameters\n","        ------\n","        node_flag_feat:\n","            ノードの特徴量(node数, フラグ次元数)\n","        node_cont_feat:\n","            ノードの特徴量(node数, 連続次元数)\n","        node_cat_feat:\n","            ノードの特徴量(node数, カテゴリ次元数*埋め込み次元数)\n","        node_config_feat:\n","            設定毎のノードの特徴量(設定数, node数, 特徴次元数)\n","        node_config_cont_feat:\n","            設定毎のノードの特徴量(設定数, node数, 連続次元数)\n","        edge_index:\n","            エッジ(2, エッジ数)\n","        node_splits:\n","            サブグラフのインデックス（サブグラフ数, 2)\n","\n","        Returns:\n","        torch.tensor: (設定数)\n","        \"\"\"\n","        # (ノード数,特徴数)のテンソルを作成\n","        node_feat = self._join_node_feature(\n","            node_opcode=node_opcode,\n","            node_flag_feat=node_flag_feat,\n","            node_cont_feat=node_cont_feat,\n","            node_cat_feat=node_cat_feat,\n","        )\n","\n","        # (設定数,ノード数,特徴数)のテンソルを作成\n","        (\n","            node_config_feat,\n","            output_layout_feat,\n","            input_layout_feat,\n","        ) = self._join_node_config_feature(\n","            node_config_feat=node_config_feat,\n","            node_config_cont_feat=node_config_cont_feat,\n","        )\n","\n","        # node_featの抽出器を通す\n","        extracted_node_feat = self.node_feat_extractor(node_feat)\n","\n","        # node_config_featの抽出器を通す\n","        extracted_node_config_feat = self.node_config_feat_extractor(node_config_feat)\n","\n","        # 設定毎のノード特徴に結合する\n","        extracted_feat = self._join_entire_node_config_feat(\n","            node_feat=extracted_node_feat,\n","            node_config_feat=extracted_node_config_feat,\n","        )\n","\n","        # GNN抽出器を通す\n","        conved_extracted_feat = self.gnn_extractor(\n","            x=extracted_feat,\n","            x_output_layout=output_layout_feat,\n","            x_input_layout=input_layout_feat,\n","            edge_index=edge_index,\n","        )\n","\n","        # 残差を足すイメージ\n","        concat_feat = torch.concat([extracted_feat, conved_extracted_feat], 2)\n","\n","        # subgraph_global_pool_feat_list = []\n","        # for subgraph_start_node_idx, subgraph_end_node_idx in node_splits:\n","        #     subgraph_concat_feat = concat_feat[\n","        #         :, subgraph_start_node_idx : subgraph_end_node_idx + 1, :\n","        #     ]\n","        #     # ノードの特徴量を足し合わせる(Global mean Pooling)\n","        #     subgraph_global_pool_feat = torch.mean(concat_feat, dim=1)\n","        #     subgraph_global_pool_feat_list.append(\n","        #         torch.reshape(\n","        #             subgraph_global_pool_feat,\n","        #             (\n","        #                 subgraph_global_pool_feat.shape[0],\n","        #                 1,\n","        #                 subgraph_global_pool_feat.shape[1],\n","        #             ),\n","        #         )\n","        #     )\n","        # # （設定数,サブグラフ数,特徴数)\n","        # subgraph_global_pool_feat = torch.concat(subgraph_global_pool_feat_list, 1)\n","        # subgraph_extracted_feat = self.subgraph_extractor(subgraph_global_pool_feat)\n","\n","        # ノードの特徴量を足し合わせる(Global mean Pooling)\n","        # global_pool_feat = torch.mean(subgraph_extracted_feat, dim=1)\n","        global_pool_feat = torch.mean(concat_feat, dim=1)\n","\n","        return torch.squeeze(self.fc(global_pool_feat))\n","\n","    def _join_node_feature(\n","        self,\n","        node_opcode: torch.Tensor,\n","        node_flag_feat: torch.Tensor,\n","        node_cont_feat: torch.Tensor,\n","        node_cat_feat: torch.Tensor,\n","    ) -> torch.Tensor:\n","        \"\"\"node_featのテンソルを作成\"\"\"\n","        # ノードの埋め込み表現\n","        node_embeddings_list = []\n","        node_embeddings_list.append(self.embeddings[\"op\"](node_opcode))\n","        for cat_name, cat_index in self.cat_status.index_dict.items():\n","            node_embeddings = self.embeddings[cat_name](node_cat_feat[:, cat_index])\n","            node_embeddings = torch.reshape(\n","                node_embeddings,\n","                (-1, node_embeddings.shape[-2] * node_embeddings.shape[-1]),\n","            )\n","            node_embeddings_list.append(node_embeddings)\n","\n","        # ノード毎で埋め込み、結合(ノード数, 特徴数)\n","        node_embedding_feat = torch.concat(node_embeddings_list, 1)\n","        node_feat = torch.concat(\n","            [node_flag_feat, node_cont_feat, node_embedding_feat], 1\n","        )\n","        return node_feat\n","\n","    def _join_node_config_feature(\n","        self, node_config_feat: torch.Tensor, node_config_cont_feat: torch.Tensor\n","    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n","        \"\"\"node_config_featのテンソルを作成\"\"\"\n","        # 設定xノード毎で埋め込み(設定数, ノード数, 特徴数)\n","\n","        # configの埋め込みは1種類が前提\n","        indexes_list = [\n","            [0, 1, 2, 3, 4, 5],\n","            [6, 7, 8, 9, 10, 11],\n","            [12, 13, 14, 15, 16, 17],\n","        ]\n","        layout_names = [\"output_layout\", \"input_layout\", \"kernel_layout\"]\n","        layout_embeddings = {}\n","        for indexes, layout_name in zip(indexes_list, layout_names):\n","            node_embeddings = self.embeddings[\"config_cat_feat1\"](\n","                node_config_feat[:, :, indexes]\n","            )\n","            node_embeddings = torch.reshape(\n","                node_embeddings,\n","                (\n","                    node_embeddings.shape[0],\n","                    -1,\n","                    node_embeddings.shape[-2] * node_embeddings.shape[-1],\n","                ),\n","            )\n","            layout_embeddings[layout_name] = node_embeddings\n","\n","        node_config_feat = torch.concat(\n","            [\n","                layout_embeddings[\"output_layout\"],\n","                layout_embeddings[\"input_layout\"],\n","                layout_embeddings[\"kernel_layout\"],\n","                node_config_cont_feat,\n","            ],\n","            2,\n","        )\n","        output_layout_feat = torch.concat(\n","            [layout_embeddings[\"output_layout\"], layout_embeddings[\"output_layout\"]], 2\n","        )\n","        input_layout_feat = torch.concat(\n","            [layout_embeddings[\"input_layout\"], layout_embeddings[\"kernel_layout\"]], 2\n","        )\n","        return node_config_feat, output_layout_feat, input_layout_feat\n","\n","    def _join_entire_node_config_feat(\n","        self, node_feat: torch.Tensor, node_config_feat: torch.Tensor\n","    ) -> torch.Tensor:\n","        # ノード毎の特徴量を設定数だけ縦に並べる\n","        node_tiled_feat = torch.tile(\n","            torch.reshape(node_feat, (1, node_feat.shape[0], node_feat.shape[1])),\n","            (node_config_feat.shape[0], 1, 1),\n","        )\n","        return torch.concat([node_tiled_feat, node_config_feat], 2)"]},{"cell_type":"markdown","metadata":{},"source":["## 学習\n"]},{"cell_type":"code","execution_count":11,"metadata":{"tags":[]},"outputs":[],"source":["class ListMLE(nn.Module):\n","    def __init__(self) -> None:\n","        super().__init__()\n","\n","    def forward(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","\n","        Parameters\n","        ----------\n","        logits: torch.Tensor\n","            予測（要素数, ）\n","        labels: torch.Tensor\n","            目的変数（要素数, ）\n","\n","        Returns\n","        -------\n","        torch.Tensor\n","        \"\"\"\n","        # 正解をソート\n","        labels_sorted, labels_sorted_indice = labels.sort(descending=True, dim=1)\n","        # 予測を正解順でソート\n","        logits_sorted_by_true = torch.gather(logits, dim=1, index=labels_sorted_indice)\n","        # 予測値の最大値で予測値を引く（expの爆発予防）\n","        logits_max, _ = logits_sorted_by_true.max(dim=1, keepdim=True)\n","        logits_sorted_by_true = logits_sorted_by_true - logits_max\n","        # ランキングが低いものから累積する(その後正解順に戻す)\n","        cumsums = torch.cumsum(logits_sorted_by_true.exp().flip(dims=[1]), dim=1).flip(\n","            dims=[1]\n","        )\n","        # 誤差\n","        negative_log_likelihood = torch.sum(\n","            torch.log(cumsums) - logits_sorted_by_true, dim=1\n","        )\n","        return torch.mean(negative_log_likelihood)\n","\n","\n","def rankNet(y_pred, y_true):\n","    \"\"\"\n","    RankNet loss introduced in \"Learning to Rank using Gradient Descent\".\n","    :param y_pred: predictions from the model, shape [batch_size, slate_length]\n","    :param y_true: ground truth labels, shape [batch_size, slate_length]\n","    :return: loss value, a torch.Tensor\n","    \"\"\"\n","    y_pred = y_pred.clone()\n","    y_true = y_true.clone()\n","\n","    # here we generate every pair of indices from the range of document length in the batch\n","    document_pairs_candidates = list(\n","        itertools.product(range(y_true.shape[1]), repeat=2)\n","    )\n","\n","    pairs_true = y_true[:, document_pairs_candidates]\n","    selected_pred = y_pred[:, document_pairs_candidates]\n","\n","    # here we calculate the relative true relevance of every candidate pair\n","    true_diffs = pairs_true[:, :, 0] - pairs_true[:, :, 1]\n","    pred_diffs = selected_pred[:, :, 0] - selected_pred[:, :, 1]\n","\n","    # here we filter just the pairs that are 'positive' and did not involve a padded instance\n","    # we can do that since in the candidate pairs we had symetric pairs so we can stick with\n","    # positive ones for a simpler loss function formulation\n","    the_mask = (true_diffs > 0) & (~torch.isinf(true_diffs))\n","\n","    pred_diffs = pred_diffs[the_mask]\n","\n","    weight = None\n","    # here we 'binarize' true relevancy diffs since for a pairwise loss we just need to know\n","    # whether one document is better than the other and not about the actual difference in\n","    # their relevancy levels\n","    true_diffs = (true_diffs > 0).type(torch.float32)\n","    true_diffs = true_diffs[the_mask]\n","\n","    return nn.BCEWithLogitsLoss(weight=weight)(pred_diffs, true_diffs)\n","\n","\n","def to_cpu_numpy(\n","    params: Params, pred: torch.Tensor, truth: torch.Tensor\n",") -> tuple[np.ndarray, np.ndarray]:\n","    if params.device == GPU:\n","        pred_ = pred.cpu().detach().numpy()\n","        truth_ = truth.cpu().detach().numpy()\n","        torch.cuda.empty_cache()\n","    else:\n","        pred_ = pred.detach().numpy()\n","        truth_ = truth.detach().numpy()\n","    return pred_, truth_"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["from scipy.stats import kendalltau\n","\n","\n","def evaluate_score(dataset: LayoutDataset, model: torch.nn.Module) -> pd.DataFrame:\n","    \"\"\"データセット全件に対してコンペの評価指標を算出する\n","    https://www.kaggle.com/competitions/predict-ai-model-runtime/overview\n","    \"\"\"\n","    model.eval()\n","    # criterion = ListMLE()\n","\n","    records = []\n","    eval_preds = []\n","    # 各グラフ毎にスコアを算出\n","    for graph_index in range(len(dataset)):\n","        # グラフ毎に1000件をバッチに分けて取得\n","        preds, truths = [], []\n","        for (\n","            node_opcode,\n","            node_flag_feat,\n","            node_cont_feat,\n","            node_cat_feat,\n","            node_config_feat,\n","            node_config_cont_feat,\n","            edge_index,\n","            node_splits,\n","            target,\n","        ) in dataset.getitem_as_random_batch(graph_index):\n","            pred = model(\n","                node_opcode=node_opcode,\n","                node_flag_feat=node_flag_feat,\n","                node_cont_feat=node_cont_feat,\n","                node_cat_feat=node_cat_feat,\n","                node_config_feat=node_config_feat,\n","                node_config_cont_feat=node_config_cont_feat,\n","                edge_index=edge_index,\n","                node_splits=node_splits,\n","            )\n","            pred, truth = to_cpu_numpy(params, pred, target)\n","            preds.append(pred)\n","            truths.append(truth)\n","\n","        preds, truths = np.hstack(preds), np.hstack(truths)\n","\n","        loss = rankNet(\n","            torch.tensor(preds.reshape(1, -1)),\n","            torch.tensor(truths.reshape(1, -1)),\n","        )\n","        graph_loss = loss.item()\n","        score = kendalltau(truths, preds).correlation\n","\n","        record = dataset.get_ith_file_info(graph_index)\n","        record.update(\n","            {\n","                \"graph_loss\": graph_loss,\n","                \"score\": score,\n","            }\n","        )\n","        records.append(record)\n","        eval_preds.append(preds)\n","    return pd.DataFrame(records), eval_preds"]},{"cell_type":"markdown","metadata":{},"source":["### 学習\n"]},{"cell_type":"code","execution_count":13,"metadata":{"tags":[]},"outputs":[],"source":["def seed_everything(seed=1234):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","\n","def train_model(\n","    dftrain: pd.DataFrame,\n","    dfvalid: pd.DataFrame,\n","    params: Params,\n","    const: Const,\n","    cat_status: CatStatus,\n","    cat_config_status: CatStatus,\n","    savedir: Path,\n","    checkpoint_dir: Path = None,\n",") -> None:\n","    train_layout_dataset = LayoutDataset(\n","        dataset=dftrain,\n","        params=params,\n","        cat_status=cat_status,\n","        cat_config_status=cat_config_status,\n","    )\n","    valid_layout_dataset = LayoutDataset(\n","        dataset=dfvalid,\n","        params=params,\n","        cat_status=cat_status,\n","        cat_config_status=cat_config_status,\n","    )\n","\n","    model = SimpleLayoutModel(\n","        params=params,\n","        const=const,\n","        cat_status=cat_status,\n","        cat_config_status=cat_config_status,\n","    )\n","    if checkpoint_dir is not None:\n","        print(\"学習済みモデルを読み込みます\")\n","        model.load_state_dict(torch.load(checkpoint_dir / f\"final_model.pt\"))\n","\n","    optimizer = torch.optim.Adam(\n","        model.parameters(), lr=params.lr, weight_decay=params.weight_decay\n","    )\n","    scheduler = CosineAnnealingLR(\n","        optimizer=optimizer, T_max=params.T_max, eta_min=params.eta_min\n","    )\n","    # criterion = ListMLE()\n","\n","    best_score = -np.inf\n","    records = []\n","    for epoch in range(params.epoch):\n","        model.train()\n","\n","        num_graph = len(train_layout_dataset)\n","        pbar = tqdm(range(num_graph))\n","        graph_indexes = random.sample(list(range(num_graph)), num_graph)\n","\n","        epoch_losses = []\n","        epoch_loss = 0  # 各グラフの誤差を総和（エポックの誤差）\n","\n","        # グラフをシャッフルして取得\n","        for i_graph, graph_index in enumerate(graph_indexes):\n","            graph_info = train_layout_dataset.get_ith_file_info(graph_index)\n","            graph_arch, graph_perm = graph_info[\"arch\"], graph_info[\"perm\"]\n","            # 各グラフで1000件をバッチに分けて取得\n","            preds, truths = [], []\n","            graph_loss = 0  # バッチの誤差を総和（グラフの誤差）\n","            num_batch_count = 0\n","            for (\n","                node_opcode,\n","                node_flag_feat,\n","                node_cont_feat,\n","                node_cat_feat,\n","                node_config_feat,\n","                node_config_cont_feat,\n","                edge_index,\n","                node_splits,\n","                target,\n","            ) in train_layout_dataset.getitem_as_random_batch(graph_index):\n","                out = model(\n","                    node_opcode=node_opcode,\n","                    node_flag_feat=node_flag_feat,\n","                    node_cont_feat=node_cont_feat,\n","                    node_cat_feat=node_cat_feat,\n","                    node_config_feat=node_config_feat,\n","                    node_config_cont_feat=node_config_cont_feat,\n","                    edge_index=edge_index,\n","                    node_splits=node_splits,\n","                )\n","                # loss = criterion(\n","                #     torch.reshape(out, (1, out.shape[0])),\n","                #     torch.reshape(target, (1, target.shape[0])),\n","                # )\n","                loss = rankNet(\n","                    torch.reshape(out, (1, out.shape[0])),\n","                    torch.reshape(target, (1, target.shape[0])),\n","                )\n","                loss.backward()\n","                graph_loss += loss.item()\n","\n","                pred, truth = to_cpu_numpy(params, out, target)\n","                preds.append(pred)\n","                truths.append(truth)\n","                num_batch_count += 1\n","\n","            # 各グラフ毎に勾配降下\n","            nn.utils.clip_grad_norm_(\n","                model.parameters(),\n","                max_norm=params.grad_clip_max_norm,\n","                norm_type=params.grad_clip_norm_type,\n","            )\n","            optimizer.step()\n","            scheduler.step(epoch + i_graph / num_graph)\n","            optimizer.zero_grad()\n","\n","            preds, truths = np.hstack(preds), np.hstack(truths)\n","            score = kendalltau(truths, preds).correlation\n","            graph_loss /= num_batch_count  # 各バッチの平均をグラフの誤差とする\n","            epoch_loss += graph_loss\n","\n","            record = {\n","                \"epoch\": epoch,\n","                \"i_graph\": i_graph,\n","                f\"train-{graph_arch}-{graph_perm}/epoch_loss\": epoch_loss\n","                / (i_graph + 1),\n","                f\"train/epoch_loss\": epoch_loss / (i_graph + 1),\n","                f\"train-{graph_arch}-{graph_perm}/graph_loss\": graph_loss,\n","                f\"train/graph_loss\": graph_loss,\n","                f\"train-{graph_arch}-{graph_perm}/score\": score,\n","                f\"train/score\": score,\n","                \"lr\": scheduler.get_last_lr()[0],\n","                f\"train-{graph_arch}-{graph_perm}/pred\": preds,\n","                f\"train/pred\": preds,\n","            }\n","            record.update(graph_info)\n","            records.append(record)\n","\n","            wandb.log(record)\n","            pbar.set_description(\n","                f\"running loss: {epoch_loss / (i_graph + 1):.5f}, graph loss: {graph_loss:.5f} score: {score:.3f}\"\n","            )\n","            pbar.update(1)\n","\n","        model.eval()\n","        torch.cuda.empty_cache()\n","\n","        dfscore, eval_preds = evaluate_score(dataset=valid_layout_dataset, model=model)\n","        avg_loss = dfscore[\"graph_loss\"].mean()\n","        avg_score = dfscore[\"score\"].mean()\n","        for i_eval, row_score in dfscore.iterrows():\n","            graph_arch, graph_perm = row_score[\"arch\"], row_score[\"perm\"]\n","            record = {\n","                \"epoch\": epoch,\n","                \"i_graph\": -1,\n","                \"arch\": graph_arch,\n","                \"perm\": graph_perm,\n","                \"filename\": row_score[\"filename\"],\n","                f\"valid-{graph_arch}-{graph_perm}/epoch_loss\": avg_loss,\n","                f\"valid/epoch_loss\": avg_loss,\n","                f\"valid-{graph_arch}-{graph_perm}/graph_loss\": row_score[\"graph_loss\"],\n","                f\"valid/graph_loss\": row_score[\"graph_loss\"],\n","                f\"valid-{graph_arch}-{graph_perm}/score\": row_score[\"score\"],\n","                f\"valid/score\": row_score[\"score\"],\n","                \"lr\": scheduler.get_last_lr()[0],\n","                f\"valid-{graph_arch}-{graph_perm}/pred\": eval_preds[i_eval],\n","                f\"valid/pred\": eval_preds[i_eval],\n","            }\n","            records.append(record)\n","            wandb.log(record)\n","\n","        print(f\"[valid] current loss: {avg_loss:.5f} score: {avg_score:.3f}\")\n","\n","        if best_score < avg_score:\n","            best_score = avg_score\n","            torch.save(model.state_dict(), savedir / \"best_model.pt\")\n","        torch.save(model.state_dict(), savedir / f\"epoch{epoch + 1}_model.pt\")\n","\n","    dflog = pd.DataFrame(records)\n","    dflog.to_csv(savedir / \"log.csv\", index=False)\n","\n","    torch.save(model.state_dict(), savedir / \"final_model.pt\")\n","\n","    del (\n","        train_layout_dataset,\n","        valid_layout_dataset,\n","        model,\n","        optimizer,\n","        dfscore,\n","        dflog,\n","        records,\n","    )\n","    gc.collect()\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzuuuubo-tetsu\u001b[0m (\u001b[33msun-scan-clan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.16.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.12"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/yamaguchi/kaggle/experiments/1109-勾配クリップ-ミスマッチ/wandb/run-20231109_230721-s2kfq5m4</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/s2kfq5m4' target=\"_blank\">1109-勾配クリップ-ミスマッチ-ノード20000以下</a></strong> to <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan' target=\"_blank\">https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/s2kfq5m4' target=\"_blank\">https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/s2kfq5m4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sun-scan-clan/predict-ai-model-runtime-for-sun-scan-clan/runs/s2kfq5m4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f7a8bd5b210>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["exptname = \"1109-勾配クリップ-ミスマッチ-ノード20000以下\"\n","\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"predict-ai-model-runtime-for-sun-scan-clan\",\n","    # track hyperparameters and run metadata\n","    config={\n","        \"params\": asdict(params),\n","        \"const\": asdict(const),\n","        \"validation\": \"hold-out\",\n","    },\n","    name=exptname,\n","    tags=[\"all\"],\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["19662 12067\n"]},{"data":{"text/plain":["(429, 38)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["thresh = 20000\n","\n","num_train_nodes = np.array(num_nodes[\"train\"])\n","train_indice = num_train_nodes < thresh\n","\n","num_valid_nodes = np.array(num_nodes[\"valid\"])\n","valid_indice = num_valid_nodes < thresh\n","print(np.max(num_train_nodes[train_indice]), np.max(num_valid_nodes[valid_indice]))\n","\n","dftrain = dataset_dict[\"train\"].loc[train_indice]\n","dfvalid = dataset_dict[\"valid\"].loc[valid_indice]\n","\n","np.argmax(num_train_nodes[train_indice]), np.argmax(num_valid_nodes[valid_indice]),"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["((482, 7), (46, 7))"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# dftrain = dftrain.iloc[[429]]\n","dftrain.shape, dfvalid.shape"]},{"cell_type":"code","execution_count":19,"metadata":{"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa76f1488e9d4586937e7cd8ef871763","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.50331 score: 0.525\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30fee0ae737d4e07b1634ae8f44552c8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.43825 score: 0.561\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c92aac72709416eb7c9dccef5e5d4f4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.43427 score: 0.562\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e67dc569fdf49da8b4b3b3cff31de2a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.42983 score: 0.567\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92ccd2f6ad564168a649c90a71b7b8e1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.43122 score: 0.573\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"213dad1d3e194b0093986a31a3b4275c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.40921 score: 0.566\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7532dc41e6694d2db486673be3d3c4b1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.40513 score: 0.585\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e4119f56804429da6ac97941c690e94","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.45332 score: 0.591\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebc2078d18f745b1a03fb58cb909b181","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.43150 score: 0.584\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77d9ef4d23314307b03610f4c8f7fa58","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.41603 score: 0.601\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4359df86e3924961bc3fbaa42034de0c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.42089 score: 0.604\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf2f97b9fda14cdb8c2860318debe9a2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.41697 score: 0.610\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1662caca2f541febe3f999669dfb002","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.44364 score: 0.611\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57e63f3001094db0a16bc16e82f9fd2a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.41325 score: 0.613\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c70f8c27e3e478db3cc15b7d251bc08","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.43575 score: 0.613\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96316d3df6f14262b3ac1ba6b5d4dad6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.42578 score: 0.615\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a386a573fbe44862887aa56413029a58","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.42878 score: 0.619\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2cd226cf228e471aa7110b9cf2f5565d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.43342 score: 0.617\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a18ee6f8c1e748a49786265bab2b264b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.43004 score: 0.618\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c04deb0270e9421797dd4ddb3fede8d5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/482 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[valid] current loss: 0.43226 score: 0.617\n"]}],"source":["seed_everything(43)\n","\n","\n","train_model(\n","    dftrain=dftrain,\n","    dfvalid=dfvalid,\n","    params=params,\n","    const=const,\n","    cat_status=cat_status,\n","    cat_config_status=cat_config_status,\n","    savedir=workdir,\n","    checkpoint_dir=None,\n",")\n","wandb.alert(title=exptname, text=f\"Train End\")"]},{"cell_type":"markdown","metadata":{},"source":["## 推論\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["savedir = workdir\n","\n","records = []\n","\n","dftest = dataset_dict[\"test\"]\n","\n","test_layout_dataset = LayoutDataset(\n","    dataset=dftest,\n","    params=params,\n","    cat_status=cat_status,\n","    cat_config_status=cat_config_status,\n",")\n","model = SimpleLayoutModel(\n","    params=params,\n","    const=const,\n","    cat_status=cat_status,\n","    cat_config_status=cat_config_status,\n",")\n","model.load_state_dict(torch.load(workdir / \"final_model.pt\"))\n","model.eval()\n","\n","with tqdm(range(len(test_layout_dataset))) as pbar:\n","    for i in pbar:\n","        file_info = test_layout_dataset.get_ith_file_info(i)\n","\n","        pred_list = []\n","        for (\n","            node_opcode,\n","            node_flag_feat,\n","            node_cont_feat,\n","            node_cat_feat,\n","            node_config_feat,\n","            node_config_cont_feat,\n","            edge_index,\n","            node_splits,\n","            target,\n","        ) in test_layout_dataset.getitem_as_batch(i):\n","            pred_batch = model(\n","                node_opcode=node_opcode,\n","                node_flag_feat=node_flag_feat,\n","                node_cont_feat=node_cont_feat,\n","                node_cat_feat=node_cat_feat,\n","                node_config_feat=node_config_feat,\n","                node_config_cont_feat=node_config_cont_feat,\n","                edge_index=edge_index,\n","                node_splits=node_splits,\n","            )\n","            if params.device == \"cuda\":\n","                pred_batch = pred_batch.cpu().detach().numpy()\n","            else:\n","                pred_batch = pred_batch.detach().numpy()\n","            # pred_batchは高いものほどよい\n","            pred_batch = -pred_batch\n","            pred_list.append(pred_batch)\n","\n","            del (\n","                node_opcode,\n","                node_flag_feat,\n","                node_cont_feat,\n","                node_cat_feat,\n","                node_config_feat,\n","                node_config_cont_feat,\n","                edge_index,\n","                node_splits,\n","                target,\n","            )\n","            gc.collect()\n","            torch.cuda.empty_cache()\n","\n","        pred = np.hstack(pred_list)\n","\n","        ID = f\"layout:{file_info['arch']}:{file_info['perm']}:{file_info['filename']}\"\n","        records.append({\"ID\": ID, \"pred\": \";\".join(list(map(str, pred.argsort())))})\n","\n","del test_layout_dataset, model\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","dfpred = pd.DataFrame(records)\n","dfsub = pd.read_csv(inputdir / \"sample_submission.csv\")\n","dfsub = dfsub.merge(dfpred, on=\"ID\", how=\"left\")\n","dfsub[\"TopConfigs\"] = np.where(\n","    dfsub[\"pred\"].isnull(), dfsub[\"TopConfigs\"], dfsub[\"pred\"]\n",")\n","dfsub[[\"ID\", \"TopConfigs\"]].to_csv(savedir / f\"submission_final_model.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.alert(title=exptname, text=f\"Inference End\")\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
